{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8474c1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13fc3704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read 18092077 characters from ./data/cleaned_train.txt\n",
      "First 500 characters:\n",
      "وَلَوْ جَمَعَ ثُمَّ عَلِمَ تَرْكَ رُكْنٍ مِنْ الْأُولَى بَطَلَتَا وَيُعِيدُهُمَا جَامِعًا ، أَوْ مِنْ الثَّانِيَةِ ، فَإِنْ لَمْ يَطُلْ تَدَارَكَ ، وَإِلَّا فَبَاطِلَةٌ وَلَا جَمَعَ ، وَلَوْ جَهِلَ أَعَادَهُمَا لِوَقْتَيْهِمَا\n",
      "قَالَ أَبُو زَيْدٍ أَهْلُ تِهَامَةَ يُؤَنِّثُونَ الْعَضُدَ وَبَنُو تَمِيمٍ يُذَكِّرُونَ ، وَالْجَمْعُ أَعْضُدٌ وَأَعْضَادٌ مِثْلُ أَفْلُسٍ وَأَقْفَالٍ\n",
      "بِمَنْزِلَةِ أَهْلِ الذِّمَّةِ إذَا دَخَلُوا قَرْيَةً مِنْ قُرَى أَهْلِ الْحَرْبِ ثُمَّ ظَفِرَ الْمُسْلِمُونَ بِهَا فَهُمْ\n"
     ]
    }
   ],
   "source": [
    "def read_cleaned_train(file_path='./data/cleaned_train.txt'):\n",
    "    \"\"\"Read text from cleaned_train.txt file.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "        print(f\"Successfully read {len(text)} characters from {file_path}\")\n",
    "        return text\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Read the file\n",
    "text = read_cleaned_train()\n",
    "if text:\n",
    "    print(f\"First 500 characters:\\n{text[:500]}\")\n",
    "text = text[:180920]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e1c5ce",
   "metadata": {},
   "source": [
    "## Diacritic and Letter Mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77483f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of diacritics: 21\n",
      "Number of letters: 43\n"
     ]
    }
   ],
   "source": [
    "class DiacriticMapper:\n",
    "    def __init__(self):\n",
    "        self.unicode_diacrits = self._build_diacritics()\n",
    "        self.unicode_letters = self._build_letters()\n",
    "        \n",
    "        self.diacrits_to_index = {char: idx for idx, char in enumerate(self.unicode_diacrits)}\n",
    "        self.index_to_diacrits = {idx: char for idx, char in enumerate(self.unicode_diacrits)}\n",
    "        \n",
    "        self.letters_to_index = {char: idx for idx, char in enumerate(self.unicode_letters)}\n",
    "        self.index_to_letter = {idx: char for idx, char in enumerate(self.unicode_letters)}\n",
    "    \n",
    "    def _build_diacritics(self):\n",
    "        diacritics = [chr(code) for code in range(0x064B, 0x0652 + 1)]\n",
    "        # Add Shadda combinations (Shadda first)\n",
    "        diacritics.extend([\n",
    "            chr(0x0651) + chr(0x064E),  # Shadda + Fatha\n",
    "            chr(0x0651) + chr(0x064F),  # Shadda + Damma\n",
    "            chr(0x0651) + chr(0x0650),  # Shadda + Kasra\n",
    "            chr(0x0651) + chr(0x064B),  # Shadda + Tanween Fath\n",
    "            chr(0x0651) + chr(0x064C),  # Shadda + Tanween Damm\n",
    "            chr(0x0651) + chr(0x064D),  # Shadda + Tanween Kasr\n",
    "        ])\n",
    "        # Add reverse order combinations (Vowel first)\n",
    "        diacritics.extend([\n",
    "            chr(0x064E) + chr(0x0651),  # Fatha + Shadda\n",
    "            chr(0x064F) + chr(0x0651),  # Damma + Shadda\n",
    "            chr(0x0650) + chr(0x0651),  # Kasra + Shadda\n",
    "            chr(0x064B) + chr(0x0651),  # Tanween Fath + Shadda\n",
    "            chr(0x064C) + chr(0x0651),  # Tanween Damm + Shadda\n",
    "            chr(0x064D) + chr(0x0651),  # Tanween Kasr + Shadda\n",
    "        ])\n",
    "        diacritics.append(\"\")  # No diacritic\n",
    "        return diacritics\n",
    "    \n",
    "    def _build_letters(self):\n",
    "        return [chr(code) for code in range(0x0620, 0x064A + 1)]\n",
    "    \n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return len(self.unicode_letters)\n",
    "    \n",
    "    @property\n",
    "    def num_classes(self):\n",
    "        return len(self.unicode_diacrits)\n",
    "\n",
    "mapper = DiacriticMapper()\n",
    "print(f\"Number of diacritics: {mapper.num_classes}\")\n",
    "print(f\"Number of letters: {mapper.vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0ec0d7",
   "metadata": {},
   "source": [
    "## Text Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fcbefdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input length: 83584, Target length: 83584\n"
     ]
    }
   ],
   "source": [
    "class TextProcessor:\n",
    "    def __init__(self, mapper):\n",
    "        self.mapper = mapper\n",
    "        self.pattern = r'[\\u0620-\\u064A][\\u064B-\\u0652]*'\n",
    "    \n",
    "    def extract_features(self, text):\n",
    "        matches = re.findall(self.pattern, text)\n",
    "        inputs = []\n",
    "        targets = []\n",
    "        \n",
    "        for match in matches:\n",
    "            inputs.append(self.mapper.letters_to_index[match[0]])\n",
    "            \n",
    "            if len(match) == 1:\n",
    "                targets.append(self.mapper.diacrits_to_index[''])\n",
    "            elif len(match) == 2:\n",
    "                targets.append(self.mapper.diacrits_to_index[match[1]])\n",
    "            elif len(match) == 3:\n",
    "                targets.append(self.mapper.diacrits_to_index[match[1] + match[2]])\n",
    "        \n",
    "        return inputs, targets\n",
    "    \n",
    "    def remove_diacritics(self, text):\n",
    "        return re.sub(r'[\\u064B-\\u0652]', \"\", text)\n",
    "    \n",
    "    def apply_diacritics(self, text, predictions):\n",
    "        pattern = r'[\\u0620-\\u064A]'\n",
    "        matches = list(re.finditer(pattern, text))\n",
    "        result = \"\"\n",
    "        last_pos = 0\n",
    "        \n",
    "        for i, match in enumerate(matches):\n",
    "            result += text[last_pos:match.start()]\n",
    "            result += match.group()\n",
    "            \n",
    "            pred_idx = predictions[i].item() if torch.is_tensor(predictions[i]) else int(predictions[i])\n",
    "            result += self.mapper.index_to_diacrits[pred_idx]\n",
    "            \n",
    "            last_pos = match.end()\n",
    "        \n",
    "        result += text[last_pos:]\n",
    "        return result\n",
    "\n",
    "processor = TextProcessor(mapper)\n",
    "input_data, target_data = processor.extract_features(text)\n",
    "print(f\"Input length: {len(input_data)}, Target length: {len(target_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1d2eb7",
   "metadata": {},
   "source": [
    "## Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "832ff36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleMaskModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, mask_classes):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, mask_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        outputs, _ = self.rnn(x)\n",
    "        logits = self.fc(outputs)\n",
    "        return logits\n",
    "\n",
    "class DiacritizationModel:\n",
    "    def __init__(self, mapper, embedding_dim=64, hidden_dim=64):\n",
    "        self.mapper = mapper\n",
    "        self.model = SingleMaskModel(\n",
    "            vocab_size=mapper.vocab_size,\n",
    "            embedding_dim=embedding_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            mask_classes=mapper.num_classes\n",
    "        )\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(inputs)\n",
    "            predictions = logits.argmax(dim=-1)\n",
    "            return predictions.numpy().reshape(-1,)\n",
    "\n",
    "diac_model = DiacritizationModel(mapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d750a45a",
   "metadata": {},
   "source": [
    "## Model Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc1734bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 83584\n",
      "\n",
      "Epoch 1/2\n",
      "  Batch 100, Loss: 1.2515\n",
      "  Batch 100, Loss: 1.2515\n",
      "  Batch 200, Loss: 1.0325\n",
      "  Batch 200, Loss: 1.0325\n",
      "  Batch 300, Loss: 0.8728\n",
      "  Batch 300, Loss: 0.8728\n",
      "  Batch 400, Loss: 0.7465\n",
      "  Batch 400, Loss: 0.7465\n",
      "  Batch 500, Loss: 0.6022\n",
      "  Batch 500, Loss: 0.6022\n",
      "  Batch 600, Loss: 0.3495\n",
      "  Batch 600, Loss: 0.3495\n",
      "Average Loss: 0.8962\n",
      "\n",
      "Epoch 2/2\n",
      "Average Loss: 0.8962\n",
      "\n",
      "Epoch 2/2\n",
      "  Batch 100, Loss: 0.6112\n",
      "  Batch 100, Loss: 0.6112\n",
      "  Batch 200, Loss: 0.5314\n",
      "  Batch 200, Loss: 0.5314\n",
      "  Batch 300, Loss: 0.4507\n",
      "  Batch 300, Loss: 0.4507\n",
      "  Batch 400, Loss: 0.3517\n",
      "  Batch 400, Loss: 0.3517\n",
      "  Batch 500, Loss: 0.2168\n",
      "  Batch 500, Loss: 0.2168\n",
      "  Batch 600, Loss: 0.0824\n",
      "  Batch 600, Loss: 0.0824\n",
      "Average Loss: 0.4043\n",
      "Average Loss: 0.4043\n"
     ]
    }
   ],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, model, learning_rate=0.001):\n",
    "        self.model = model\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    def train_step(self, input_tensor, target_tensor):\n",
    "        self.model.train()\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        logits = self.model(input_tensor)\n",
    "        logits_reshaped = logits.view(-1, logits.size(-1))\n",
    "        target_reshaped = target_tensor.view(-1)\n",
    "        \n",
    "        loss = self.criterion(logits_reshaped, target_reshaped)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return loss.item()\n",
    "    \n",
    "    def train_epoch(self, input_data, target_data, batch_size=512, seq_length=128):\n",
    "        \"\"\"Train for one epoch with batching\"\"\"\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        # Create batches\n",
    "        for i in range(0, len(input_data) - seq_length, seq_length):\n",
    "            batch_inputs = []\n",
    "            batch_targets = []\n",
    "            \n",
    "            for j in range(0, batch_size):\n",
    "                start_idx = i + j * seq_length\n",
    "                if start_idx + seq_length >= len(input_data):\n",
    "                    break\n",
    "                batch_inputs.append(input_data[start_idx:start_idx + seq_length])\n",
    "                batch_targets.append(target_data[start_idx:start_idx + seq_length])\n",
    "            \n",
    "            if not batch_inputs:\n",
    "                break\n",
    "                \n",
    "            input_tensor = torch.tensor(batch_inputs)\n",
    "            target_tensor = torch.tensor(batch_targets)\n",
    "            \n",
    "            loss = self.train_step(input_tensor, target_tensor)\n",
    "            total_loss += loss\n",
    "            num_batches += 1\n",
    "            \n",
    "            if num_batches % 100 == 0:\n",
    "                print(f\"  Batch {num_batches}, Loss: {loss:.4f}\")\n",
    "        \n",
    "        return total_loss / num_batches if num_batches > 0 else 0\n",
    "\n",
    "trainer = ModelTrainer(diac_model.model)\n",
    "\n",
    "print(f\"Training samples: {len(input_data)}\")\n",
    "\n",
    "# Train for multiple epochs\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "    avg_loss = trainer.train_epoch(input_data, target_data)\n",
    "    print(f\"Average Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72354ff5",
   "metadata": {},
   "source": [
    "## Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68d16db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    @staticmethod\n",
    "    def calculate_accuracy(target, predictions):\n",
    "        correct = sum(1 for t, p in zip(target, predictions) if t == p)\n",
    "        total = len(target)\n",
    "        acc = (correct / total) * 100 if total > 0 else 0\n",
    "        \n",
    "        print(f\"Total diacritics: {total}\")\n",
    "        print(f\"Correct predictions: {correct}\")\n",
    "        print(f\"Incorrect predictions: {total - correct}\")\n",
    "        print(f\"Diacritic Accuracy: {acc:.2f}%\")\n",
    "        \n",
    "        return acc\n",
    "\n",
    "evaluator = Evaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190b266d",
   "metadata": {},
   "source": [
    "## Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cee6048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions length: 83584\n",
      "\n",
      "Original text:\n",
      "وَلَوْ جَمَعَ ثُمَّ عَلِمَ تَرْكَ رُكْنٍ مِنْ الْأُولَى بَطَلَتَا وَيُعِيدُهُمَا جَامِعًا ، أَوْ مِنْ الثَّانِيَةِ ، فَإِنْ لَمْ يَطُلْ تَدَارَكَ ، وَإِلَّا فَبَاطِلَةٌ وَلَا جَمَعَ ، وَلَوْ جَهِلَ أَعَادَهُمَا لِوَقْتَيْهِمَا\n",
      "قَالَ أَبُو زَيْدٍ أَهْلُ تِهَامَةَ يُؤَنِّثُونَ الْعَضُدَ وَبَنُو تَمِيمٍ يُذَكِّرُونَ ، وَالْجَمْعُ أَعْضُدٌ وَأَعْضَادٌ مِثْلُ أَفْلُسٍ وَأَقْفَالٍ\n",
      "بِمَنْزِلَةِ أَهْلِ الذِّمَّةِ إذَا دَخَلُوا قَرْيَةً مِنْ قُرَى أَهْلِ الْحَرْبِ ثُمَّ ظَفِرَ الْمُسْلِمُونَ بِهَا فَهُمْ\n",
      "\n",
      "Predicted text:\n",
      "وَلَوْ جَمَعْ ثُمَّ عُلُمْ تُرَكٍ رَكْنّ مِنْ الْأَوْلَى بَطَلَتَا وَيَعِيَدُهُمَا جَامَعًا ، أَو مِنْ الثَّانِيَةِ ، فَإِنْ لَمْ يُطُلُ تُدَارَكَ ، وْإلَا فَبَاطَلَةٍ وَلَا جَمْعَ ، وَلَوْ جَهُلَ أَعَادُهُمَا لَوَقَتَيْهِمَا\n",
      "قِالَ أَبُو زَيْدُ أَهْلِ تْهَامَةَ يُؤَنّثُونَ الَعَضْدُ وَبَنُوَ تَمِيمِ يذَكَرُونٌ ، وَالْجَمْعِ أَعْضَدُ وَأَعْضَادَ مِثُلُ أَفْلَسَ وَأَقَفَالَ\n",
      "بَمْنْزِلَةُ أَهْلَ الذَّمَةِ إذَا دَخَلَوَا قُرِّيَةُ مِنْ قَرَى أَهْلَ الحَرْبِ ثُمْ ظُفَرَ الْمَسْلَمُوَنَ بِهَا فَهُمْ فَ\n",
      "Total diacritics: 83584\n",
      "Correct predictions: 63820\n",
      "Incorrect predictions: 19764\n",
      "Diacritic Accuracy: 76.35%\n",
      "\n",
      "Training Accuracy: 76.35%\n"
     ]
    }
   ],
   "source": [
    "train_input_tensor = torch.tensor([input_data])\n",
    "predictions = diac_model.predict(train_input_tensor)\n",
    "print(f\"Predictions length: {len(predictions)}\")\n",
    "\n",
    "nonDictText = processor.remove_diacritics(text)\n",
    "final_text = processor.apply_diacritics(nonDictText, predictions)\n",
    "\n",
    "print(\"\\nOriginal text:\")\n",
    "print(text[:500])\n",
    "print(\"\\nPredicted text:\")\n",
    "print(final_text[:500])\n",
    "\n",
    "accuracy = evaluator.calculate_accuracy(target_data, predictions)\n",
    "print(f\"\\nTraining Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "565f3e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read 882191 characters from ./data/cleaned_val.txt\n",
      "First 500 characters of validation:\n",
      "الشَّهَادَةِ ظَاهِرَةً ، وَبِحَقٍّ بَيِّنٍ تَضْعُفُ التُّهْمَةُ ، وَهُوَ الْفَرْقُ بَيْنَهُ وَبَيْنَ الشَّهَادَةِ ، وَعَنْ أَصْبَغَ الْجَوَازُ فِي الْوَلَدِ وَالزَّوْجَةِ وَالْأَخِ وَالْمُكَاتَبِ وَالْمُدَبَّرِ وَالْمِدْيَانِ إنْ كَانَ مِنْ أَهْلِ الْقِيَامِ بِالْحَقِّ ، وَصَحَّ الْحُكْمُ ، وَقَدْ يَحْكُمُ لِلْخَلِيفَةِ ، وَهُوَ فَوْقَهُ ، وَتُهْمَتُهُ أَقْوَى ، وَلَا يَنْبَغِي لَهُ الْقَضَاءُ بَيْنَ أَحَدٍ مِنْ عَشِيرَتِهِ وَخَصْمِهِ ، وَإِنْ رَضِيَ الْخَصْمُ بِخِلَافِ رَجُلَيْنِ رَضِيَا بِحُكْ\n",
      "\n",
      "Validation - Input length: 407434, Target length: 407434\n",
      "Validation predictions length: 407434\n",
      "Validation predictions length: 407434\n",
      "\n",
      "==================================================\n",
      "VALIDATION RESULTS\n",
      "==================================================\n",
      "\n",
      "Original validation text:\n",
      "الشَّهَادَةِ ظَاهِرَةً ، وَبِحَقٍّ بَيِّنٍ تَضْعُفُ التُّهْمَةُ ، وَهُوَ الْفَرْقُ بَيْنَهُ وَبَيْنَ الشَّهَادَةِ ، وَعَنْ أَصْبَغَ الْجَوَازُ فِي الْوَلَدِ وَالزَّوْجَةِ وَالْأَخِ وَالْمُكَاتَبِ وَالْمُدَبَّرِ وَالْمِدْيَانِ إنْ كَانَ مِنْ أَهْلِ الْقِيَامِ بِالْحَقِّ ، وَصَحَّ الْحُكْمُ ، وَقَدْ يَحْكُمُ لِلْخَلِيفَةِ ، وَهُوَ فَوْقَهُ ، وَتُهْمَتُهُ أَقْوَى ، وَلَا يَنْبَغِي لَهُ الْقَضَاءُ بَيْنَ أَحَدٍ مِنْ عَشِيرَتِهِ وَخَصْمِهِ ، وَإِنْ رَضِيَ الْخَصْمُ بِخِلَافِ رَجُلَيْنِ رَضِيَا بِحُكْ\n",
      "\n",
      "Predicted validation text:\n",
      "الشَّهَادَةِ ظَاهِرَةُ ، وَبَحُقْ بِيْنِ تِضِعَفْ التِهِمَةِ ، وَهُوَ الْفَرْقُ بَيْنَهُ وَبَيْنُ الشَّهَادَةِ ، وَعَنْ أَصْبِغَ الْجَوَازِ فِي الْوَلدِ وَالْزُوجَةِ وَالْأُخُ وَالْمُكَاتَبُ وَالْمَدَّبَرِ وَالْمُدْيانِ إِنْ كَانَ مِنْ أَهْلِ الْقِيَامِ بِالْحَقِّ ، وَصِحَ الْحُكْمِ ، وَقَدِ يَحُكِمَ لِلْخَلِيفَةُ ، وَهُوَ فَوقَهُ ، وَتَهَمَتُهُ أَقْوى ، وَلَا يُنْبَغَيْ لَهِ الَقْضَاءُ بَيْنِ أَحَدِ مِنْ عَشِيرَتَهِ وَخَصْمَهُ ، وَإِنْ رَضِيَ الْخَصَمِ بِخِلَافِ رَجْلِينَ رَضِيَا بِحُكُمُ رْجُل\n",
      "\n",
      "==================================================\n",
      "Total diacritics: 407434\n",
      "Correct predictions: 288396\n",
      "Incorrect predictions: 119038\n",
      "Diacritic Accuracy: 70.78%\n",
      "\n",
      "Validation Accuracy: 70.78%\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "VALIDATION RESULTS\n",
      "==================================================\n",
      "\n",
      "Original validation text:\n",
      "الشَّهَادَةِ ظَاهِرَةً ، وَبِحَقٍّ بَيِّنٍ تَضْعُفُ التُّهْمَةُ ، وَهُوَ الْفَرْقُ بَيْنَهُ وَبَيْنَ الشَّهَادَةِ ، وَعَنْ أَصْبَغَ الْجَوَازُ فِي الْوَلَدِ وَالزَّوْجَةِ وَالْأَخِ وَالْمُكَاتَبِ وَالْمُدَبَّرِ وَالْمِدْيَانِ إنْ كَانَ مِنْ أَهْلِ الْقِيَامِ بِالْحَقِّ ، وَصَحَّ الْحُكْمُ ، وَقَدْ يَحْكُمُ لِلْخَلِيفَةِ ، وَهُوَ فَوْقَهُ ، وَتُهْمَتُهُ أَقْوَى ، وَلَا يَنْبَغِي لَهُ الْقَضَاءُ بَيْنَ أَحَدٍ مِنْ عَشِيرَتِهِ وَخَصْمِهِ ، وَإِنْ رَضِيَ الْخَصْمُ بِخِلَافِ رَجُلَيْنِ رَضِيَا بِحُكْ\n",
      "\n",
      "Predicted validation text:\n",
      "الشَّهَادَةِ ظَاهِرَةُ ، وَبَحُقْ بِيْنِ تِضِعَفْ التِهِمَةِ ، وَهُوَ الْفَرْقُ بَيْنَهُ وَبَيْنُ الشَّهَادَةِ ، وَعَنْ أَصْبِغَ الْجَوَازِ فِي الْوَلدِ وَالْزُوجَةِ وَالْأُخُ وَالْمُكَاتَبُ وَالْمَدَّبَرِ وَالْمُدْيانِ إِنْ كَانَ مِنْ أَهْلِ الْقِيَامِ بِالْحَقِّ ، وَصِحَ الْحُكْمِ ، وَقَدِ يَحُكِمَ لِلْخَلِيفَةُ ، وَهُوَ فَوقَهُ ، وَتَهَمَتُهُ أَقْوى ، وَلَا يُنْبَغَيْ لَهِ الَقْضَاءُ بَيْنِ أَحَدِ مِنْ عَشِيرَتَهِ وَخَصْمَهُ ، وَإِنْ رَضِيَ الْخَصَمِ بِخِلَافِ رَجْلِينَ رَضِيَا بِحُكُمُ رْجُل\n",
      "\n",
      "==================================================\n",
      "Total diacritics: 407434\n",
      "Correct predictions: 288396\n",
      "Incorrect predictions: 119038\n",
      "Diacritic Accuracy: 70.78%\n",
      "\n",
      "Validation Accuracy: 70.78%\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Read validation data\n",
    "def read_cleaned_val(file_path='./data/cleaned_val.txt'):\n",
    "    \"\"\"Read text from cleaned_val.txt file.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            val_text = f.read()\n",
    "        print(f\"Successfully read {len(val_text)} characters from {file_path}\")\n",
    "        return val_text\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file: {e}\")\n",
    "        return None\n",
    "\n",
    "val_text = read_cleaned_val()\n",
    "if val_text:\n",
    "    print(f\"First 500 characters of validation:\\n{val_text[:500]}\")\n",
    "    \n",
    "    # Extract features from validation data\n",
    "    val_input_data, val_target_data = processor.extract_features(val_text)\n",
    "    print(f\"\\nValidation - Input length: {len(val_input_data)}, Target length: {len(val_target_data)}\")\n",
    "    \n",
    "    # Predict on validation data\n",
    "    val_input_tensor = torch.tensor([val_input_data])\n",
    "    val_predictions = diac_model.predict(val_input_tensor)\n",
    "    print(f\"Validation predictions length: {len(val_predictions)}\")\n",
    "    \n",
    "    # Apply diacritics to validation text\n",
    "    val_nonDictText = processor.remove_diacritics(val_text)\n",
    "    val_final_text = processor.apply_diacritics(val_nonDictText, val_predictions)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"VALIDATION RESULTS\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"\\nOriginal validation text:\")\n",
    "    print(val_text[:500])\n",
    "    print(\"\\nPredicted validation text:\")\n",
    "    print(val_final_text[:500])\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    val_accuracy = evaluator.calculate_accuracy(val_target_data, val_predictions)\n",
    "    print(f\"\\nValidation Accuracy: {val_accuracy:.2f}%\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7963b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
