{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "8474c1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "2a8b06ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"بوَإِنْ كَانَ الْمَأْذُونُ هُوَ الْوَكِيلَ لِلْأَجْنَبِيِّ بِبَيْعِ شَيْءٍ أَوْ شِرَائِهِ مِنْ مَوْلَاهُ جَازَ ؛ لِأَنَّهُ لَا حَقَّ لِلْعَبْدِ فِي مَالِ مَوْلَاهُ وَكَانَتْ الْعُهْدَةُ عَلَيْهِ مَدْيُونًا كَانَ أَوْ غَيْرَ مَدْيُونٍ وَإِنْ أَقَرَّ بِالْقَبْضِ جَازَ إقْرَارُهُ ؛ لِأَنَّهُ يَصْلُحُ وَكِيلًا لِلْأَجْنَبِيِّ فِي قَبْضِ الدَّيْنِ مِنْ الْمَوْلَى وَيَصْلُحُ مُطَالِبًا لِلْمَوْلَى بِالثَّمَنِ إذَا بَاعَ مِنْهُ شَيْئًا مِنْ أَكْسَابِهِ وَعَلَيْهِ دَيْنٌ لِمُرَاعَاةِ حَقِّ غُرَمَائِهِ فَكَذَلِكَ لِمُرَاعَاةِ حَقِّ الْمُوَكِّلِ ، وَكَذَلِكَ لَوْ لَمْ يَدْفَعْ الْآمِرُ إلَى الْعَبْدِ شَيْئًا مِنْ الثَّمَنِ وَوَكَّلَهُ بِأَنْ يَشْتَرِيَ لَهُ مِنْ مَوْلَاهُ جَازَ شِرَاؤُهُ وَأَخَذَ الثَّمَنَ مِنْ الْآمِرِ وَدَفَعَهُ إلَى الْمَوْلَى ؛ لِأَنَّهُ فِي التَّوْكِيلِ بِالْمُعَامَلَةِ مَعَ الْمَوْلَى كَهُوَ فِي التَّوْكِيلِ بِالْمُعَامَلَةِ مَعَ أَجْنَبِيٍّ آخَرَ \"\n",
    "\n",
    "# Print each character with its Unicode code point\n",
    "matches = re.findall(r'[\\u0620-\\u064A][\\u064B-\\u0652]*', text)\n",
    "max = np.max([len(match) for match in matches])\n",
    "# print(max)\n",
    "# for match in matches:\n",
    "#     #if len(match) == 1:\n",
    "#         print(len(match), end =': ')\n",
    "#         for char in match:\n",
    "#             print(f\"{char}\", end = '')\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "d6cf21cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"بوَإِنْ كَانَ الْمَأْذُونُ هُوَ الْوَكِيلَ لِلْأَجْنَبِيِّ بِبَيْعِ شَيْءٍ أَوْ شِرَائِهِ مِنْ مَوْلَاهُ جَازَ ؛ لِأَنَّهُ لَا حَقَّ لِلْعَبْدِ فِي مَالِ مَوْلَاهُ وَكَانَتْ الْعُهْدَةُ عَلَيْهِ مَدْيُونًا كَانَ أَوْ غَيْرَ مَدْيُونٍ وَإِنْ أَقَرَّ بِالْقَبْضِ جَازَ إقْرَارُهُ ؛ لِأَنَّهُ يَصْلُحُ وَكِيلًا لِلْأَجْنَبِيِّ فِي قَبْضِ الدَّيْنِ مِنْ الْمَوْلَى وَيَصْلُحُ مُطَالِبًا لِلْمَوْلَى بِالثَّمَنِ إذَا بَاعَ مِنْهُ شَيْئًا مِنْ أَكْسَابِهِ وَعَلَيْهِ دَيْنٌ لِمُرَاعَاةِ حَقِّ غُرَمَائِهِ فَكَذَلِكَ لِمُرَاعَاةِ حَقِّ الْمُوَكِّلِ ، وَكَذَلِكَ لَوْ لَمْ يَدْفَعْ الْآمِرُ إلَى الْعَبْدِ شَيْئًا مِنْ الثَّمَنِ وَوَكَّلَهُ بِأَنْ يَشْتَرِيَ لَهُ مِنْ مَوْلَاهُ جَازَ شِرَاؤُهُ وَأَخَذَ الثَّمَنَ مِنْ الْآمِرِ وَدَفَعَهُ إلَى الْمَوْلَى ؛ لِأَنَّهُ فِي التَّوْكِيلِ بِالْمُعَامَلَةِ مَعَ الْمَوْلَى كَهُوَ فِي التَّوْكِيلِ بِالْمُعَامَلَةِ مَعَ أَجْنَبِيٍّ آخَرَ \"\n",
    "\n",
    "# Print each character with its Unicode code point\n",
    "matches = re.findall(r'[\\u0620-\\u064A][\\u064B-\\u0652]*', text)\n",
    "# for char in text:\n",
    "#     print(f\"{char}: U+{ord(char):04X}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "77483f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unicode list: ['ً', 'ٌ', 'ٍ', 'َ', 'ُ', 'ِ', 'ّ', 'ْ', 'َّ', 'ُّ', 'ِّ', 'ًّ', 'ٌّ', 'ٍّ', '']\n",
      "Unicode to index: {'ً': 0, 'ٌ': 1, 'ٍ': 2, 'َ': 3, 'ُ': 4, 'ِ': 5, 'ّ': 6, 'ْ': 7, 'َّ': 8, 'ُّ': 9, 'ِّ': 10, 'ًّ': 11, 'ٌّ': 12, 'ٍّ': 13, '': 14}\n",
      "Index to Unicode: {0: 'ً', 1: 'ٌ', 2: 'ٍ', 3: 'َ', 4: 'ُ', 5: 'ِ', 6: 'ّ', 7: 'ْ', 8: 'َّ', 9: 'ُّ', 10: 'ِّ', 11: 'ًّ', 12: 'ٌّ', 13: 'ٍّ', 14: ''}\n"
     ]
    }
   ],
   "source": [
    "start = 0x064B\n",
    "end = 0x0652\n",
    "\n",
    "unicode_diacrits = [chr(code) for code in range(start, end + 1)]\n",
    "unicode_diacrits.append(chr(0x0651) + chr(0x064E)) \n",
    "unicode_diacrits.append(chr(0x0651) + chr(0x064F)) \n",
    "unicode_diacrits.append(chr(0x0651) + chr(0x0650)) \n",
    "unicode_diacrits.append(chr(0x0651) + chr(0x064B))\n",
    "unicode_diacrits.append(chr(0x0651) + chr(0x064C))\n",
    "unicode_diacrits.append(chr(0x0651) + chr(0x064D))\n",
    "unicode_diacrits.append(\"\")\n",
    "\n",
    "diacrits_to_index = {char: idx for idx, char in enumerate(unicode_diacrits)}\n",
    "index_to_diacrits  = {idx: char for idx, char in enumerate(unicode_diacrits)}\n",
    "\n",
    "print(\"Unicode list:\", unicode_diacrits)\n",
    "print(\"Unicode to index:\", diacrits_to_index)\n",
    "print(\"Index to Unicode:\", index_to_diacrits)\n",
    "\n",
    "letters_start = 0x0620\n",
    "letters_end = 0x064A\n",
    "\n",
    "unicode_letters = unicode_chars = [chr(code) for code in range(letters_start, letters_end + 1)]\n",
    "\n",
    "letters_to_index = {char: idx for idx, char in enumerate(unicode_letters)}\n",
    "index_to_letter = {idx: char for idx, char in enumerate(unicode_letters)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "9fcbefdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414\n",
      "414\n"
     ]
    }
   ],
   "source": [
    "matches = re.findall(r'[\\u0620-\\u064A][\\u064B-\\u0652]*', text)\n",
    "input = []\n",
    "target = []\n",
    "\n",
    "for match in matches:\n",
    "    if len(match) == 1:\n",
    "        input.append(letters_to_index[match[0]])\n",
    "        target.append(diacrits_to_index[''])\n",
    "    elif len(match) == 2:\n",
    "        input.append(letters_to_index[match[0]])\n",
    "        target.append(diacrits_to_index[match[1]])\n",
    "    elif len(match) == 3:\n",
    "        input.append(letters_to_index[match[0]])\n",
    "        target.append(diacrits_to_index[match[1]+match[2]])\n",
    "\n",
    "print(len(input))\n",
    "print(len(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "9798d641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.7198\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the sequence labeling model\n",
    "class SingleMaskModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, mask_classes):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, mask_classes)  # bidirectional doubles hidden_dim\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)                  # Convert input indices to embeddings\n",
    "        outputs, _ = self.rnn(x)               # Capture context with bidirectional LSTM\n",
    "        logits = self.fc(outputs)              # Predict diacritic class per letter\n",
    "        return logits\n",
    "\n",
    "# Sample vocab sizes (adjust as needed)\n",
    "vocab_size = len(unicode_letters)        # Number of letters in alphabet\n",
    "embedding_dim = len(unicode_letters)     # Embedding size for each letter\n",
    "hidden_dim = 64        # Hidden layer size in LSTM\n",
    "mask_classes = len(unicode_diacrits)     # Number of possible diacritics (including no diacritic)\n",
    "\n",
    "# Initialize model\n",
    "model = SingleMaskModel(vocab_size, embedding_dim, hidden_dim, mask_classes)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Example input: batch size 1, sequence length 3 (letters indices)\n",
    "input_tensor = torch.tensor([input])      # Example letters: [translate:ك], [translate:ت], [translate:ب]\n",
    "\n",
    "# Example target diacritics: sequence length 3 (mask indices per letter)\n",
    "target_tensor = torch.tensor([target])     # Diacritics for each letter\n",
    "\n",
    "# Training step\n",
    "model.train()\n",
    "optimizer.zero_grad()\n",
    "logits = model(input_tensor)                   # Forward pass: get predicted logits (batch, seq_len, mask_classes)\n",
    "logits_reshaped = logits.view(-1, mask_classes)    # Reshape for loss: (batch*seq_len, mask_classes)\n",
    "target_reshaped = target_tensor.view(-1)            # Flatten target: (batch*seq_len)\n",
    "loss = criterion(logits_reshaped, target_reshaped)  # Compute cross-entropy loss\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "print(f\"Training loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "447ac686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, inputs):\n",
    "   with torch.no_grad():\n",
    "        logits = model(inputs)\n",
    "        predictions = logits.argmax(dim=-1) \n",
    "        return predictions.numpy().reshape(-1, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "ff38eef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414\n"
     ]
    }
   ],
   "source": [
    "predictions = predict(model, input_tensor)\n",
    "print(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "1cee6048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diacritizatize(nonDictText, predictions):\n",
    "    pattern = r'[\\u0620-\\u064A]'\n",
    "    \n",
    "    matches = list(re.finditer(pattern, nonDictText))\n",
    "    result = \"\"\n",
    "    last_pos = 0\n",
    "    \n",
    "    for i, match in enumerate(matches):\n",
    "        result += nonDictText[last_pos:match.start()]\n",
    "        \n",
    "        result += match.group()\n",
    "        \n",
    "        # Add the predicted diacritic\n",
    "        pred_idx = predictions[i].item() if torch.is_tensor(predictions[i]) else int(predictions[i])\n",
    "        result += index_to_diacrits[pred_idx]\n",
    "\n",
    "        last_pos = match.end()\n",
    "    \n",
    "    result += nonDictText[last_pos:]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "07dd6715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "بوإن كان المأذون هو الوكيل للأجنبي ببيع شيء أو شرائه من مولاه جاز ؛ لأنه لا حق للعبد في مال مولاه وكانت العهدة عليه مديونا كان أو غير مديون وإن أقر بالقبض جاز إقراره ؛ لأنه يصلح وكيلا للأجنبي في قبض الدين من المولى ويصلح مطالبا للمولى بالثمن إذا باع منه شيئا من أكسابه وعليه دين لمراعاة حق غرمائه فكذلك لمراعاة حق الموكل ، وكذلك لو لم يدفع الآمر إلى العبد شيئا من الثمن ووكله بأن يشتري له من مولاه جاز شراؤه وأخذ الثمن من الآمر ودفعه إلى المولى ؛ لأنه في التوكيل بالمعاملة مع المولى كهو في التوكيل بالمعاملة مع أجنبي آخر \n",
      "بّوَّإًّنُ كٍاُنُ اِلَمْأْذْوٌّنْ هُوَّ اّلَّوَّكٍيًّلَّ لَّلَّأِّجّنُبّيًّ بٍبٍيًّعَّ شُّيْءُ أِّوٌّ شَّرًّاِئٍهُ مْنْ مْوّلَّاِهُ جّاِز ؛ لَّأِّنُهُ لَّاُ حُقُّ لَّلَّعَّبُدًّ فًّيًّ مَاِلَ مْوّلَّاُهُ وَّكٍاِنُتُ اُلَّعُهُدّةًّ عَّلَّيًّهُ مُدِيْوٌّنُاُ كَاِنْ أْوَّ غًّيًّرًّ مَدِيْوٌّنُ وَّإًّنْ أِّقْرًّ بّاُلقْبّضْ جّاِز إًّقْرًّاًّرْهُ ؛ لَّأِّنُهُ يًّصًّلَّحِّ وِّكٍيًّلَّاّ لَّلَّأِّجّنُبّيًّ فًّيْ قُبٍضْ اًّلًّدِيْنُ مْنُ اُلَمْوَّلَّىِّ وٌّيًّصًّلَّحٍ مِّطّاِلبّاًّ لَلمْوَّلَّىٍ بّاًّلًّثمَنْ إًّذْاِ بُاُعُ مْنْهُ شُّيًّئُاُ مْنْ أَكَسْاِبُهُ وَّعَّلَّيًّهُ دُيًّنُ لَّمَرْاُعُاُةْ حُقُّ غٍرًّمِاِئّهُ فْكَذَّلَّكَ لَمَرْاُعُاُةْ حُقُّ اّلمْوَّكٍلَّ ، وَّكٍذَّلَّكَ لَّوَّ لَّمَ يًّدِفًّعَّ اًّلًّآًّمْرًّ إًّلًّىّ اِلعبُدِ شًّيًّئًّاُ مْنْ اًّلًّثُمْنْ وٌّوَّكٍلَّهُ بُأِّنُ يًّشُّتًّرًّيًّ لُهُ مُنُ مْوّلَّاِهُ جّاِز شُّرًّاِؤِّهُ وَّأِّخًّذُ اًّلًّثُمْنُ مْنْ اًّلَآْمْرْ وٌّدًّفًّعٍهُ إًّلَّىّ اًّلَمَوَّلَّىِّ ؛ لَّأِّنْهُ فْيًّ اِلتُوَّكٍيًّلَّ بّاًّلمَعَّاًّمَلَةْ مَعَّ اُلَمْوَّلَّىِّ كَهُوَّ فًّيًّ اِلتُوَّكٍيًّلَّ بّاًّلمَعَّاُمَلَةْ مْعَّ أِّجّنُبًّيًّ آًّخٍرٍ \n",
      "بوَإِنْ كَانَ الْمَأْذُونُ هُوَ الْوَكِيلَ لِلْأَجْنَبِيِّ بِبَيْعِ شَيْءٍ أَوْ شِرَائِهِ مِنْ مَوْلَاهُ جَازَ ؛ لِأَنَّهُ لَا حَقَّ لِلْعَبْدِ فِي مَالِ مَوْلَاهُ وَكَانَتْ الْعُهْدَةُ عَلَيْهِ مَدْيُونًا كَانَ أَوْ غَيْرَ مَدْيُونٍ وَإِنْ أَقَرَّ بِالْقَبْضِ جَازَ إقْرَارُهُ ؛ لِأَنَّهُ يَصْلُحُ وَكِيلًا لِلْأَجْنَبِيِّ فِي قَبْضِ الدَّيْنِ مِنْ الْمَوْلَى وَيَصْلُحُ مُطَالِبًا لِلْمَوْلَى بِالثَّمَنِ إذَا بَاعَ مِنْهُ شَيْئًا مِنْ أَكْسَابِهِ وَعَلَيْهِ دَيْنٌ لِمُرَاعَاةِ حَقِّ غُرَمَائِهِ فَكَذَلِكَ لِمُرَاعَاةِ حَقِّ الْمُوَكِّلِ ، وَكَذَلِكَ لَوْ لَمْ يَدْفَعْ الْآمِرُ إلَى الْعَبْدِ شَيْئًا مِنْ الثَّمَنِ وَوَكَّلَهُ بِأَنْ يَشْتَرِيَ لَهُ مِنْ مَوْلَاهُ جَازَ شِرَاؤُهُ وَأَخَذَ الثَّمَنَ مِنْ الْآمِرِ وَدَفَعَهُ إلَى الْمَوْلَى ؛ لِأَنَّهُ فِي التَّوْكِيلِ بِالْمُعَامَلَةِ مَعَ الْمَوْلَى كَهُوَ فِي التَّوْكِيلِ بِالْمُعَامَلَةِ مَعَ أَجْنَبِيٍّ آخَرَ \n"
     ]
    }
   ],
   "source": [
    "nonDictText = re.sub(r'[\\u064B-\\u0652]', \"\", text)\n",
    "print(nonDictText)\n",
    "final_text = diacritizatize(nonDictText, predictions)\n",
    "print(final_text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "8a8f8d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total diacritics: 414\n",
      "Correct predictions: 43\n",
      "Incorrect predictions: 371\n",
      "Diacritic Accuracy: 10.39%\n",
      "10.38647342995169\n"
     ]
    }
   ],
   "source": [
    "def accuracy(target, predictions):\n",
    "    correct = 0\n",
    "    total = len(target)\n",
    "    \n",
    "    for i in range(total):\n",
    "        if target[i] == predictions[i]:\n",
    "            correct += 1\n",
    "    \n",
    "    acc = (correct / total) * 100 if total > 0 else 0\n",
    "    \n",
    "    print(f\"Total diacritics: {total}\")\n",
    "    print(f\"Correct predictions: {correct}\")\n",
    "    print(f\"Incorrect predictions: {total - correct}\")\n",
    "    print(f\"Diacritic Accuracy: {acc:.2f}%\")\n",
    "    \n",
    "    return acc\n",
    "print(accuracy(target, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565f3e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
