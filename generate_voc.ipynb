{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d97bc477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences: 50001\n",
      "First 3 sentences:\n",
      "Sentence 0: وَلَوْ جَمَعَ ثُمَّ عَلِمَ تَرْكَ رُكْنٍ مِنْ الْأ...\n",
      "Sentence 1: قَالَ أَبُو زَيْدٍ أَهْلُ تِهَامَةَ يُؤَنِّثُونَ ا...\n",
      "Sentence 2: بِمَنْزِلَةِ أَهْلِ الذِّمَّةِ إذَا دَخَلُوا قَرْي...\n"
     ]
    }
   ],
   "source": [
    "with open('data/cleaned_train.txt', 'r', encoding='utf-8') as f:\n",
    "    big_string = f.read()\n",
    "\n",
    "sentences = big_string.split('\\n')\n",
    "\n",
    "print(f\"Total sentences: {len(sentences)}\")\n",
    "print(\"First 3 sentences:\")\n",
    "for i in range(3):\n",
    "    print(f\"Sentence {i}: {sentences[i][:50]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0931134e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty sentences: 1\n"
     ]
    }
   ],
   "source": [
    "empty_sentences = [s for s in sentences if len(s.strip()) == 0]\n",
    "print(f\"Empty sentences: {len(empty_sentences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b809ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences after removing empty ones: 50000\n"
     ]
    }
   ],
   "source": [
    "sentences = list(filter(lambda s: s.strip(), sentences))\n",
    "print(f\"Total sentences after removing empty ones: {len(sentences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6873b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "BPE tokenizer trained!\n",
      "Vocabulary size: 20000\n",
      "First sentence: وَلَوْ جَمَعَ ثُمَّ عَلِمَ تَرْكَ رُكْنٍ مِنْ الْأُولَى بَطَلَتَا وَيُعِيدُهُمَا جَامِعًا ، أَوْ مِنْ الثَّانِيَةِ ، فَإِنْ لَمْ يَطُلْ تَدَارَكَ ، وَإِلَّا فَبَاطِلَةٌ وَلَا جَمَعَ ، وَلَوْ جَهِلَ أَعَادَهُمَا لِوَقْتَيْهِمَا\n",
      "First sentence tokens: ['وَلَوْ', 'جَمَعَ', 'ثُمَّ', 'عَلِمَ', 'تَرْكَ', 'رُكْنٍ', 'مِنْ', 'الْأُولَى', 'بَطَلَ', 'تَا', 'وَيُ', 'عِيدُ', 'هُمَا', 'جَامِ', 'عًا', '،', 'أَوْ', 'مِنْ', 'الثَّانِيَةِ', '،', 'فَإِنْ', 'لَمْ', 'يَطُلْ', 'تَدَا', 'رَكَ', '،', 'وَإِلَّا', 'فَ', 'بَاطِلَةٌ', 'وَلَا', 'جَمَعَ', '،', 'وَلَوْ', 'جَهِلَ', 'أَعَادَ', 'هُمَا', 'لِ', 'وَقْتَ', 'يْهِمَا']\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "tokenizer = Tokenizer(BPE())\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "trainer = BpeTrainer(\n",
    "    vocab_size=20000,\n",
    "    special_tokens=[\"[UNK]\", \"[PAD]\", \"[CLS]\", \"[SEP]\"]\n",
    ")\n",
    "\n",
    "tokenizer.train_from_iterator(sentences, trainer)\n",
    "tokenizer.save('tokenizer.json') \n",
    "\n",
    "print(\"BPE tokenizer trained!\")\n",
    "print(f\"Vocabulary size: {tokenizer.get_vocab_size()}\")\n",
    "\n",
    "test_tokens = tokenizer.encode(sentences[0]).tokens\n",
    "print(f\"First sentence: {sentences[0]}\")\n",
    "print(f\"First sentence tokens: {test_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b76a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('utils/arabic_letters.pickle', 'rb') as f:\n",
    "    letters = pickle.load(f)\n",
    "\n",
    "letter2idx = {letter: idx for idx, letter in enumerate(letters)}\n",
    "\n",
    "with open('utils/letter2idx.pickle', 'wb') as f:\n",
    "    pickle.dump(letter2idx, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
