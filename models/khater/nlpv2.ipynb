{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a87d558",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter \n",
    "import re\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af034ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_clean.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "train_data = ' '.join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95660475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "الشّهَادَةِ ظَاهِرَةً ، وَبِحَقّ بَيّنٍ تَضْعُفُ التّهْمَةُ ، وَهُوَ الْفَرْقُ بَيْنَهُ وَبَيْنَ الشّهَادَةِ ، وَعَنْ أَصْبَغَ الْجَوَازُ فِي الْوَلَدِ وَالزّوْجَةِ وَالْأَخِ وَالْمُكَاتَبِ وَالْمُدَبّرِ وَالْمِدْيَانِ إنْ كَانَ مِنْ أَهْلِ الْقِيَامِ بِالْحَقّ ، وَصَحّ الْحُكْمُ ، وَقَدْ يَحْكُمُ لِلْخَلِيفَةِ ، وَهُوَ فَوْقَهُ ، وَتُهْمَتُهُ أَقْوَى ، وَلَا يَنْبَغِي لَهُ الْقَضَاءُ بَيْنَ أَحَدٍ مِنْ عَشِيرَتِهِ وَخَصْمِهِ ، وَإِنْ رَضِيَ الْخَصْمُ بِخِلَافِ رَجُلَيْنِ رَضِيَا بِحُكْمِ رَجُلٍ أَجْنَبِيّ فَيَنْفُذُ ذَلِكَ عَلَيْهِمَا ، وَلَا يَقْضِي بَيْنَهُ وَبَيْنَ غَيْرِهِ ، وَإِنْ رَضِيَ الْخَصْمُ بِذَلِكَ فَإِنْ فَعَلَ فَيُشْهِدُ عَلَى رِضَاهُ ، وَيَجْتَهِدُ فِي الْحَقّ فَإِنْ قَضَى لِنَفْسِهِ أَوْ لِمَنْ يَمْتَنِعُ قَضَاؤُهُ لَهُ فَلْيَذْكُرْ الْقِصّةَ كُلّهَا ، وَرَضِيَ خَصْمِهِ ، وَشَهَادَةَ مَنْ شَهِدَ بِرِضَى الْخَصْمِ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('val_clean.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "val_data = ' '.join(lines)\n",
    "print(lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f9a2063",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = re.sub(r'\\d', '', train_data)\n",
    "val_data = re.sub(r'\\d', '', val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "077d8ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.find('3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c926a563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "MAX_WORDS = 100      # أقصى عدد كلمات للجملة\n",
    "MAX_CHARS = 500     # أقصى عدد حروف للجملة\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    # Split by sentence delimiters\n",
    "    sentences = re.split(r\"[\\.!؟۔،؛\\n]+\", text)\n",
    "    sentences = [s.strip() for s in sentences if len(s.strip()) > 0]\n",
    "    \n",
    "    result = []\n",
    "    for sentence in sentences:\n",
    "        # If sentence is within limits, add it directly\n",
    "        if len(sentence.split()) <= MAX_WORDS and len(sentence) <= MAX_CHARS:\n",
    "            result.append(sentence)\n",
    "        else:\n",
    "            # Split long sentence into smaller chunks\n",
    "            result.extend(split_long_sentence(sentence))\n",
    "    \n",
    "    return result\n",
    "\n",
    "def split_long_sentence(sentence):\n",
    "    \"\"\"Split a long sentence into smaller chunks based on natural breaks.\"\"\"\n",
    "    chunks = []\n",
    "    \n",
    "    # Try splitting by commas or semicolons first\n",
    "    parts = re.split(r'([،,;؛])', sentence)\n",
    "    \n",
    "    current_chunk = \"\"\n",
    "    for i, part in enumerate(parts):\n",
    "        # Check if this is a delimiter\n",
    "        if part in '،,;؛':\n",
    "            current_chunk += part\n",
    "            continue\n",
    "        \n",
    "        potential_chunk = current_chunk + part\n",
    "        \n",
    "        # Check if adding this part exceeds limits\n",
    "        if (len(potential_chunk.split()) > MAX_WORDS or \n",
    "            len(potential_chunk) > MAX_CHARS) and current_chunk:\n",
    "            # Save current chunk and start new one\n",
    "            chunks.append(current_chunk.strip())\n",
    "            current_chunk = part\n",
    "        else:\n",
    "            current_chunk = potential_chunk\n",
    "    \n",
    "    # Add the last chunk\n",
    "    if current_chunk.strip():\n",
    "        chunks.append(current_chunk.strip())\n",
    "    \n",
    "    # If chunks are still too long, split by word count\n",
    "    final_chunks = []\n",
    "    for chunk in chunks:\n",
    "        if len(chunk.split()) <= MAX_WORDS and len(chunk) <= MAX_CHARS:\n",
    "            final_chunks.append(chunk)\n",
    "        else:\n",
    "            final_chunks.extend(split_by_words(chunk))\n",
    "    \n",
    "    return final_chunks\n",
    "\n",
    "def split_by_words(text):\n",
    "    \"\"\"Split text by word count as a last resort.\"\"\"\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    \n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "    \n",
    "    for word in words:\n",
    "        potential_length = current_length + len(word) + 1  # +1 for space\n",
    "        \n",
    "        if (len(current_chunk) >= MAX_WORDS or \n",
    "            potential_length > MAX_CHARS) and current_chunk:\n",
    "            chunks.append(' '.join(current_chunk))\n",
    "            current_chunk = [word]\n",
    "            current_length = len(word)\n",
    "        else:\n",
    "            current_chunk.append(word)\n",
    "            current_length = potential_length\n",
    "    \n",
    "    if current_chunk:\n",
    "        chunks.append(' '.join(current_chunk))\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c8f0dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = split_into_sentences(train_data)\n",
    "val_sentences = split_into_sentences(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f61d4d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146083\n",
      "7339\n"
     ]
    }
   ],
   "source": [
    "print(len(train_sentences))\n",
    "print(len(val_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77524d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "وَلَوْ جَمَعَ ثُمّ عَلِمَ تَرْكَ رُكْنٍ مِنْ الْأُولَى بَطَلَتَا وَيُعِيدُهُمَا جَامِعًا\n",
      "أَوْ مِنْ الثّانِيَةِ\n",
      "فَإِنْ لَمْ يَطُلْ تَدَارَكَ\n",
      "وَإِلّا فَبَاطِلَةٌ وَلَا جَمَعَ\n",
      "وَلَوْ جَهِلَ أَعَادَهُمَا لِوَقْتَيْهِمَا\n",
      "قَالَ أَبُو زَيْدٍ أَهْلُ تِهَامَةَ يُؤَنّثُونَ الْعَضُدَ وَبَنُو تَمِيمٍ يُذَكّرُونَ\n",
      "وَالْجَمْعُ أَعْضُدٌ وَأَعْضَادٌ مِثْلُ أَفْلُسٍ وَأَقْفَالٍ\n",
      "بِمَنْزِلَةِ أَهْلِ الذّمّةِ إذَا دَخَلُوا قَرْيَةً مِنْ قُرَى أَهْلِ الْحَرْبِ ثُمّ ظَفِرَ الْمُسْلِمُونَ بِهَا فَهُمْ فَيْءٌ أَجْمَعُونَ إلّا مِنْ عُرِفَ أَنّهُ ذِمّيّ\n",
      "الْمَسْأَلَةُ الْخَامِسَةُ قَوْله تَعَالَى الّذِينَ يُظَاهِرُونَ حَقِيقَتُهُ تَشْبِيهُ ظَهْرٍ بِظَهْرٍ\n",
      "وَالْمُوجِبُ لِلْحُكْمِ مِنْهُ تَشْبِيهُ ظَهْرِ مُحَلّلٍ بِظَهْرِ مُحَرّمٍ\n",
      "وَيَتَفَرّعُ عَلَيْهِ فُرُوعٌ كَثِيرَةٌ\n",
      "أُصُولُهَا سَبْعَةٌ الْفَرْعُ الْأَوّلُ إذَا شَبّهَ جُمْلَةَ أَهْلِهِ بِظَهْرِ أُمّهِ\n",
      "كَمَا جَاءَ فِي الْحَدِيثِ أَنّهُ قَالَ أَنْتِ عَلَيّ كَظَهْرِ أُمّي\n",
      "قَوْلُهُ وَاَلّذِي لَا يَتَغَابَنُ النّاسُ فِي مِثْلِهِ مَا لَا يَدْخُلُ تَحْتَ تَقْوِيمِ الْمُقَوّمِينَ\n",
      "لِأَنّ مَا يَدْخُلُ تَحْتَ تَقْوِيمِهِمْ زِيَادَةٌ غَيْرُ مُتَحَقّقَةٍ\n",
      "لِأَنّهُ قَدْ يُقَوّمُهُ إنْسَانٌ بِتِلْكَ الزّيَادَةِ\n",
      "وَإِنْ لَمْ تَكُنْ مُتَحَقّقَةً عُفِيَ عَنْهَا قَالَ الْخُجَنْدِيّ الّذِي يَتَغَابَنُ النّاسُ فِي مِثْلِهِ نِصْفُ الْعُشْرِ أَوْ أَقَلّ مِنْهُ\n",
      "وَإِنْ كَانَ أَكْثَرَ مِنْ نِصْفِ الْعُشْرِ فَهُوَ مِمّا لَا يَتَغَابَنُ النّاسُ فِيهِ\n",
      "وَقَالَ نُصَيْرُ بْنُ يَحْيَى قَدْرُ مَا يَتَغَابَنُ\n",
      "سُئِلَ رَحِمَهُ اللّهُ عَنْ قَوْلِهِمْ إنّ أَطْفَالَ الْكُفّارِ فِي الْجَنّةِ عَلَى الْأَصَحّ فَقِيلَ هَذَا مُشْكِلٌ بِكَلَامِ الْفُقَهَاءِ أَنّهُمْ مَحْكُومٌ بِكُفْرِهِمْ قَبْلَ الْمَوْتِ إذْ لَا يُصَلّى عَلَيْهِمْ وَلَا يُدْفَنُونَ فِي مَقَابِرِ الْمُسْلِمِينَ وَلَمْ يُوجَدْ مُزِيلٌ لَهُ وَيَلْزَمُ عَلَيْهِ أَنّ لَنَا غَيْرَ مُسْلِمٍ يَدْخُلُ الْجَنّةَ فَأُجِيبَ عَنْهُ بِأَنّهُ بَاطِلٌ عَنْهُمْ وَإِنّمَا هُمْ مَحْكُومٌ بِإِسْلَامِهِمْ لِقَوْلِهِ صَلّى اللّهُ عَلَيْهِ وَسَلّمَ كُلّ مَوْلُودٍ\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(train_sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7179ac69",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARABIC_DIACRITICS = [\n",
    "    \"َ\", \"ُ\", \"ِ\", \"ْ\", \"ّ\", \"َّ\", \"ُّ\", \"ِّ\", \"ً\", \"ٌ\", \"ٍ\"\n",
    "]\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self):\n",
    "        # Input vocab\n",
    "        self.char2idx_in = {\n",
    "            '<PAD>': 0,\n",
    "            '<EOW>': 1,\n",
    "            '<EOS>':2,\n",
    "            '<SOS>':3\n",
    "        }\n",
    "        self.idx2char_in = {\n",
    "            0: '<PAD>',\n",
    "            1: '<EOW>',\n",
    "            2: '<EOS>',\n",
    "            3: '<SOS>'\n",
    "        }\n",
    "\n",
    "        # Output vocab (diacritics only)\n",
    "        self.char2idx_out = {\n",
    "            \"\": 0,          # No diacritic (الحرف بدون أي تشكيل)\n",
    "            \"َ\": 1,         # Fatha  (فتحة)\n",
    "            \"ُ\": 2,         # Damma  (ضمة)\n",
    "            \"ِ\": 3,         # Kasra  (كسرة)\n",
    "            \"ْ\": 4,         # Sukun  (سكون)\n",
    "            \"ّ\": 5,         # Shadda (شدة فقط)\n",
    "            \"َّ\": 6,        # Shadda + Fatha (شدة + فتحة)\n",
    "            \"ُّ\": 7,        # Shadda + Damma (شدة + ضمة)\n",
    "            \"ِّ\": 8,        # Shadda + Kasra (شدة + كسرة)\n",
    "            \"ً\": 9,         # Tanween Fatha (تنوين فتح)\n",
    "            \"ٌ\": 10,        # Tanween Damma (تنوين ضم)\n",
    "            \"ٍ\": 11,        # Tanween Kasra (تنوين كسر)\n",
    "            \"<EOW>\": 12,     # End Of Word token (علامة نهاية كلمة في إخراج النموذج)\n",
    "            \"<PAD>\": 13,     # Padding token (علامة الحشو)\n",
    "            \"<SOS>\": 14,\n",
    "            '<EOS>':15\n",
    "        }\n",
    "\n",
    "        self.idx2char_out = {v: k for k, v in self.char2idx_out.items()}\n",
    "\n",
    "    def build_vocab(self, sentences_raw):\n",
    "\n",
    "        vocab_input = set()\n",
    "\n",
    "        for s_raw in sentences_raw:\n",
    "            for char in s_raw:\n",
    "                if char.strip(): \n",
    "                    vocab_input.add(char)\n",
    "\n",
    "        vocab_input = sorted(vocab_input)\n",
    "\n",
    "        # Fill vocab — starting from index 2\n",
    "        for i, char in enumerate(vocab_input, start=4):\n",
    "            self.char2idx_in[char] = i\n",
    "            self.idx2char_in[i] = char\n",
    "\n",
    "        self.vocab_size_in = len(self.char2idx_in)\n",
    "        self.vocab_size_out = len(self.char2idx_out)\n",
    "\n",
    "    def encode_input(self, text):\n",
    "        out = [self.char2idx_in['<SOS>']]\n",
    "        for c in text:\n",
    "            if c == \" \":\n",
    "                out.append(self.char2idx_in['<EOW>'])\n",
    "            else:\n",
    "                out.append(self.char2idx_in.get(c, 0))\n",
    "        out.append(self.char2idx_in['<EOS>'])\n",
    "        return out\n",
    "\n",
    "    def decode_input(self, idx_list):\n",
    "        return ''.join(\n",
    "            ' ' if i == self.char2idx_in['<EOW>'] else self.idx2char_in.get(i, '')\n",
    "            for i in idx_list\n",
    "        )\n",
    "\n",
    "    def encode_output(self, sentence):\n",
    "        tokens = [self.char2idx_out['<SOS>']]\n",
    "        i = 0\n",
    "        while i < len(sentence):\n",
    "\n",
    "            char = sentence[i]\n",
    "\n",
    "            # skip pure diacritic without base\n",
    "            if char in ARABIC_DIACRITICS:\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            # spaces: no diacritic\n",
    "            if char == \" \":\n",
    "                tokens.append(12)  # <EOW>\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            diacritics = \"\"\n",
    "            j = i + 1\n",
    "\n",
    "            while j < len(sentence) and sentence[j] in ARABIC_DIACRITICS:\n",
    "                diacritics += sentence[j]\n",
    "                j += 1\n",
    "\n",
    "            # Normalize the diacritic sequence\n",
    "            # Try to match the key exactly as it appears in char2idx_out\n",
    "            if diacritics not in self.char2idx_out:\n",
    "                # If not found, try reversing (sometimes order matters)\n",
    "                diacritics_reversed = diacritics[::-1]\n",
    "                if diacritics_reversed in self.char2idx_out:\n",
    "                    diacritics = diacritics_reversed\n",
    "                        \n",
    "            # final diacritic sequence\n",
    "            tokens.append(self.char2idx_out.get(diacritics, 0))\n",
    "\n",
    "            i = j\n",
    "        tokens.append(self.char2idx_out['<EOS>'])\n",
    "        return tokens\n",
    "\n",
    "    def decode_output(self, idx):\n",
    "        return self.idx2char_out.get(idx, \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c680384",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "706d3b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_diacritics(sentences):\n",
    "    no_diac_senteces = []\n",
    "    for sentence in sentences:\n",
    "         chars = [char for char in sentence if char not in ARABIC_DIACRITICS]\n",
    "         no_diac_senteces.append(''.join(chars))\n",
    "    return no_diac_senteces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6145cdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_diac_sentences_train = remove_diacritics(train_sentences)\n",
    "no_diac_sentences_val = remove_diacritics(val_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d246408",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.build_vocab(no_diac_sentences_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5bcc93e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ولو جمع ثم علم ترك ركن من الأولى بطلتا ويعيدهما جامعا\n",
      "الشهادة ظاهرة\n"
     ]
    }
   ],
   "source": [
    "print(no_diac_sentences_train[0])\n",
    "print(no_diac_sentences_val[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d9bab74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing all diacritics...\n",
      "\n",
      "✗ Test 1: No diacritics\n",
      "  Input: 'الكتاب'\n",
      "  Expected: [0, 0, 0, 0, 0, 0]\n",
      "  Got:      [14, 0, 0, 0, 0, 0, 0, 15]\n",
      "\n",
      "✗ Test 2: Fatha only\n",
      "  Input: 'كَتَبَ'\n",
      "  Expected: [1, 1, 1]\n",
      "  Got:      [14, 1, 1, 1, 15]\n",
      "\n",
      "✗ Test 3: Damma only\n",
      "  Input: 'كُتُبُ'\n",
      "  Expected: [2, 2, 2]\n",
      "  Got:      [14, 2, 2, 2, 15]\n",
      "\n",
      "✗ Test 4: Kasra only\n",
      "  Input: 'كِتِبِ'\n",
      "  Expected: [3, 3, 3]\n",
      "  Got:      [14, 3, 3, 3, 15]\n",
      "\n",
      "✗ Test 5: Sukun only\n",
      "  Input: 'كْتْبْ'\n",
      "  Expected: [4, 4, 4]\n",
      "  Got:      [14, 4, 4, 4, 15]\n",
      "\n",
      "✗ Test 6: Shadda alone\n",
      "  Input: 'كّتّبّ'\n",
      "  Expected: [5, 5, 5]\n",
      "  Got:      [14, 5, 5, 5, 15]\n",
      "\n",
      "✗ Test 7: Shadda + Fatha\n",
      "  Input: 'كَّتَّبَّ'\n",
      "  Expected: [6, 6, 6]\n",
      "  Got:      [14, 6, 6, 6, 15]\n",
      "\n",
      "✗ Test 8: Shadda + Damma\n",
      "  Input: 'كُّتُّبُّ'\n",
      "  Expected: [7, 7, 7]\n",
      "  Got:      [14, 7, 7, 7, 15]\n",
      "\n",
      "✗ Test 9: Shadda + Kasra\n",
      "  Input: 'كِّتِّبِّ'\n",
      "  Expected: [8, 8, 8]\n",
      "  Got:      [14, 8, 8, 8, 15]\n",
      "\n",
      "✗ Test 10: Tanween Fatha\n",
      "  Input: 'كتابًا'\n",
      "  Expected: [0, 0, 0, 0, 9, 0]\n",
      "  Got:      [14, 0, 0, 0, 9, 0, 15]\n",
      "\n",
      "✗ Test 11: Tanween Damma\n",
      "  Input: 'كتابٌ'\n",
      "  Expected: [0, 0, 0, 0, 10]\n",
      "  Got:      [14, 0, 0, 0, 10, 15]\n",
      "\n",
      "✗ Test 12: Tanween Kasra\n",
      "  Input: 'كتابٍ'\n",
      "  Expected: [0, 0, 0, 0, 11]\n",
      "  Got:      [14, 0, 0, 0, 11, 15]\n",
      "\n",
      "✗ Test 13: Mixed diacritics with space\n",
      "  Input: 'كَتَبَ الْوَلَدُ'\n",
      "  Expected: [1, 1, 1, 12, 0, 4, 1, 1, 2]\n",
      "  Got:      [14, 1, 1, 1, 12, 0, 4, 1, 1, 2, 15]\n",
      "\n",
      "✗ Test 14: As-salamu (with Shadda+Fatha)\n",
      "  Input: 'السَّلَامُ'\n",
      "  Expected: [0, 0, 6, 0, 0, 2]\n",
      "  Got:      [14, 0, 0, 6, 1, 0, 2, 15]\n",
      "\n",
      "✗ Test 15: Muhammad (with Shadda+Fatha and Tanween Damma)\n",
      "  Input: 'مُحَمَّدٌ'\n",
      "  Expected: [2, 1, 1, 6, 10]\n",
      "  Got:      [14, 2, 1, 6, 10, 15]\n",
      "\n",
      "✗ Test 16: Bismillah\n",
      "  Input: 'بِسْمِ اللَّهِ'\n",
      "  Expected: [3, 4, 3, 12, 0, 0, 6, 3]\n",
      "  Got:      [14, 3, 4, 3, 12, 0, 0, 6, 3, 15]\n",
      "\n",
      "✗ Test 17: All diacritics on same letter\n",
      "  Input: 'بَبُبِبْبّبَّبُّبِّبًبٌبٍ'\n",
      "  Expected: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "  Got:      [14, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 15]\n",
      "\n",
      "✗ Test 18: Two words with space\n",
      "  Input: 'كَتَبَ وَلَدٌ'\n",
      "  Expected: [1, 1, 1, 12, 1, 1, 10]\n",
      "  Got:      [14, 1, 1, 1, 12, 1, 1, 10, 15]\n",
      "\n",
      "✗ Test 19: Empty string\n",
      "  Input: ''\n",
      "  Expected: []\n",
      "  Got:      [14, 15]\n",
      "\n",
      "✗ Test 20: Only spaces\n",
      "  Input: '   '\n",
      "  Expected: [12, 12, 12]\n",
      "  Got:      [14, 12, 12, 12, 15]\n",
      "\n",
      "✗ Test 21: Mixed diacritized and non-diacritized\n",
      "  Input: 'كَتبُ'\n",
      "  Expected: [1, 0, 0, 2]\n",
      "  Got:      [14, 1, 0, 2, 15]\n",
      "\n",
      "\n",
      "==================================================\n",
      "Results: 0 passed, 21 failed out of 21 tests\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "def test_all_diacritics():\n",
    "    \n",
    "    test_cases = [\n",
    "        # Test case format: (input_text, expected_output, description)\n",
    "        \n",
    "        # 1. No diacritic\n",
    "        (\"الكتاب\", [0, 0, 0, 0, 0, 0], \"No diacritics\"),\n",
    "        \n",
    "        # 2. Fatha (َ)\n",
    "        (\"كَتَبَ\", [1, 1, 1], \"Fatha only\"),\n",
    "        \n",
    "        # 3. Damma (ُ)\n",
    "        (\"كُتُبُ\", [2, 2, 2], \"Damma only\"),\n",
    "        \n",
    "        # 4. Kasra (ِ)\n",
    "        (\"كِتِبِ\", [3, 3, 3], \"Kasra only\"),\n",
    "        \n",
    "        # 5. Sukun (ْ)\n",
    "        (\"كْتْبْ\", [4, 4, 4], \"Sukun only\"),\n",
    "        \n",
    "        # 6. Shadda alone (ّ)\n",
    "        (\"كّتّبّ\", [5, 5, 5], \"Shadda alone\"),\n",
    "        \n",
    "        # 7. Shadda + Fatha (َّ)\n",
    "        (\"كَّتَّبَّ\", [6, 6, 6], \"Shadda + Fatha\"),\n",
    "        \n",
    "        # 8. Shadda + Damma (ُّ)\n",
    "        (\"كُّتُّبُّ\", [7, 7, 7], \"Shadda + Damma\"),\n",
    "        \n",
    "        # 9. Shadda + Kasra (ِّ)\n",
    "        (\"كِّتِّبِّ\", [8, 8, 8], \"Shadda + Kasra\"),\n",
    "        \n",
    "        # 10. Tanween Fatha (ً)\n",
    "        (\"كتابًا\", [0, 0, 0, 0, 9, 0], \"Tanween Fatha\"),\n",
    "        \n",
    "        # 11. Tanween Damma (ٌ)\n",
    "        (\"كتابٌ\", [0, 0, 0, 0, 10], \"Tanween Damma\"),\n",
    "        \n",
    "        # 12. Tanween Kasra (ٍ)\n",
    "        (\"كتابٍ\", [0, 0, 0, 0, 11], \"Tanween Kasra\"),\n",
    "        \n",
    "        # 13. Mixed diacritics\n",
    "        (\"كَتَبَ الْوَلَدُ\", [1, 1, 1, 12, 0, 4, 1, 1, 2], \"Mixed diacritics with space\"),\n",
    "        \n",
    "        # 14. Real word: السَّلَامُ\n",
    "        (\"السَّلَامُ\", [0, 0, 6, 0, 0, 2], \"As-salamu (with Shadda+Fatha)\"),\n",
    "        \n",
    "        # 15. Real word: مُحَمَّدٌ\n",
    "        (\"مُحَمَّدٌ\", [2, 1, 1, 6, 10], \"Muhammad (with Shadda+Fatha and Tanween Damma)\"),\n",
    "        \n",
    "        # 16. Real word: بِسْمِ اللَّهِ\n",
    "        (\"بِسْمِ اللَّهِ\", [3, 4, 3, 12, 0, 0, 6, 3], \"Bismillah\"),\n",
    "        \n",
    "        # 17. Complex: all diacritics in sequence\n",
    "        (\"بَبُبِبْبّبَّبُّبِّبًبٌبٍ\", [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], \"All diacritics on same letter\"),\n",
    "        \n",
    "        # 18. Word with spaces\n",
    "        (\"كَتَبَ وَلَدٌ\", [1, 1, 1, 12, 1, 1, 10], \"Two words with space\"),\n",
    "        \n",
    "        # 19. Empty/edge cases\n",
    "        (\"\", [], \"Empty string\"),\n",
    "        (\"   \", [12, 12, 12], \"Only spaces\"),\n",
    "        \n",
    "        # 20. Letters without diacritics between diacritized ones\n",
    "        (\"كَتبُ\", [1, 0, 0, 2], \"Mixed diacritized and non-diacritized\"),\n",
    "    ]\n",
    "    \n",
    "    print(\"Testing all diacritics...\\n\")\n",
    "    passed = 0\n",
    "    failed = 0\n",
    "    \n",
    "    for i, (input_text, expected, description) in enumerate(test_cases, 1):\n",
    "        result = vocab.encode_output(input_text)\n",
    "        \n",
    "        if result == expected:\n",
    "            print(f\"✓ Test {i}: {description}\")\n",
    "            print(f\"  Input: '{input_text}'\")\n",
    "            print(f\"  Output: {result}\")\n",
    "            passed += 1\n",
    "        else:\n",
    "            print(f\"✗ Test {i}: {description}\")\n",
    "            print(f\"  Input: '{input_text}'\")\n",
    "            print(f\"  Expected: {expected}\")\n",
    "            print(f\"  Got:      {result}\")\n",
    "            failed += 1\n",
    "        print()\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Results: {passed} passed, {failed} failed out of {len(test_cases)} tests\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    return passed, failed\n",
    "\n",
    "\n",
    "# Run the tests\n",
    "if __name__ == \"__main__\":\n",
    "    test_all_diacritics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44f1a259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 37, 33, 37, 1, 15, 34, 28, 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[14, 0, 0, 6, 1, 0, 2, 15]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(vocab.encode_input('ولو جمع'))\n",
    "vocab.encode_output(\"السَّلَامُ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3f4d48d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "{'<PAD>': 0, '<EOW>': 1, '<EOS>': 2, '<SOS>': 3, 'ء': 4, 'آ': 5, 'أ': 6, 'ؤ': 7, 'إ': 8, 'ئ': 9, 'ا': 10, 'ب': 11, 'ة': 12, 'ت': 13, 'ث': 14, 'ج': 15, 'ح': 16, 'خ': 17, 'د': 18, 'ذ': 19, 'ر': 20, 'ز': 21, 'س': 22, 'ش': 23, 'ص': 24, 'ض': 25, 'ط': 26, 'ظ': 27, 'ع': 28, 'غ': 29, 'ف': 30, 'ق': 31, 'ك': 32, 'ل': 33, 'م': 34, 'ن': 35, 'ه': 36, 'و': 37, 'ى': 38, 'ي': 39}\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab.char2idx_in))\n",
    "print(vocab.char2idx_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "76e13fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows(sentence, window_size=9):\n",
    "    words = sentence.split()\n",
    "    windows = []\n",
    "    for i in range(len(words) - window_size + 1):\n",
    "        windows.append(' '.join(words[i:i + window_size]))\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e7185f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sentences_with_diacritics_train = []\n",
    "for sentence in train_sentences:\n",
    "    windows = create_windows(sentence, window_size=9)\n",
    "    window_sentences_with_diacritics_train.extend(windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2d0ac0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sentences_with_no_diacritics_train = []\n",
    "for sentence in no_diac_sentences_train:\n",
    "    windows = create_windows(sentence, window_size=9)\n",
    "    window_sentences_with_no_diacritics_train.extend(windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a92355dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sentences_with_diacritics_val = []\n",
    "for sentence in val_sentences:\n",
    "    windows = create_windows(sentence, window_size=9)\n",
    "    window_sentences_with_diacritics_val.extend(windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "670844bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sentences_with_no_diacritics_val = []\n",
    "for sentence in no_diac_sentences_val:\n",
    "    windows = create_windows(sentence, window_size=9)\n",
    "    window_sentences_with_no_diacritics_val.extend(windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a0788520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'': 0, 'َ': 1, 'ُ': 2, 'ِ': 3, 'ْ': 4, 'ّ': 5, 'َّ': 6, 'ُّ': 7, 'ِّ': 8, 'ً': 9, 'ٌ': 10, 'ٍ': 11, '<EOW>': 12, '<PAD>': 13, '<SOS>': 14, '<EOS>': 15}\n"
     ]
    }
   ],
   "source": [
    "print(vocab.char2idx_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "484b950e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'وَلَوْ جَمَعَ ثُمّ عَلِمَ تَرْكَ رُكْنٍ مِنْ الْأُولَى بَطَلَتَا'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_sentences_with_diacritics_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "383714d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55094\n",
      "55094\n",
      "1154746\n",
      "1154746\n"
     ]
    }
   ],
   "source": [
    "print(len(window_sentences_with_diacritics_val))\n",
    "print(len(window_sentences_with_no_diacritics_val))\n",
    "print(len(window_sentences_with_diacritics_train))\n",
    "print(len(window_sentences_with_no_diacritics_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "08a66aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "وَلَوْ جَمَعَ ثُمّ عَلِمَ تَرْكَ رُكْنٍ مِنْ الْأُولَى بَطَلَتَا\n"
     ]
    }
   ],
   "source": [
    "print(window_sentences_with_diacritics_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "091e7969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab.encode_input(window_sentences_with_no_diacritics_train[2])))\n",
    "print(len(vocab.encode_output(window_sentences_with_diacritics_train[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d557f52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiacritizationDataset(Dataset):\n",
    "    def __init__(self, sentences_raw, sentences_diac,vocab):\n",
    "        self.data = []\n",
    "\n",
    "        for s_raw, s_diac in zip(sentences_raw, sentences_diac):\n",
    "                input_tokens = vocab.encode_input(s_raw) \n",
    "                output_tokens = vocab.encode_output(s_diac)\n",
    "\n",
    "                if len(input_tokens) == len(output_tokens): \n",
    "                    self.data.append((input_tokens, output_tokens))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.data[idx]\n",
    "        return torch.tensor(x), torch.tensor(y)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    xs, ys = zip(*batch)\n",
    "    xs = torch.nn.utils.rnn.pad_sequence(xs, batch_first=True, padding_value=0) \n",
    "    ys = torch.nn.utils.rnn.pad_sequence(ys, batch_first=True, padding_value=13) # Padding value for output is 13\n",
    "    return xs, ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d3e74397",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = DiacritizationDataset(window_sentences_with_no_diacritics_train, window_sentences_with_diacritics_train, vocab)\n",
    "train_loader = DataLoader(dataset_train, batch_size=32, collate_fn=collate_fn, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a7768f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val = DiacritizationDataset(window_sentences_with_no_diacritics_val, window_sentences_with_diacritics_val, vocab)\n",
    "val_loader = DataLoader(dataset_val, batch_size=32, collate_fn=collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9b3748b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14, 0, 0, 6, 1, 0, 2, 12, 1, 1, 4, 2, 4, 15]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.encode_output(\"السَّلَامُ عَلَيْكُمْ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e668ef29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Batch:\n",
      "==================================================\n",
      "\n",
      "Item 0:\n",
      "  Shape: torch.Size([32, 52])\n",
      "  Data: tensor([[ 3, 30, 39,  ..., 35,  2,  0],\n",
      "        [ 3, 33,  6,  ..., 39,  2,  0],\n",
      "        [ 3,  6, 37,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [ 3, 11, 35,  ...,  0,  0,  0],\n",
      "        [ 3, 11, 35,  ...,  0,  0,  0],\n",
      "        [ 3, 24, 33,  ...,  0,  0,  0]])\n",
      "\n",
      "Item 1:\n",
      "  Shape: torch.Size([32, 52])\n",
      "  Data: tensor([[14,  3,  0,  ...,  3, 15, 13],\n",
      "        [14,  3,  1,  ...,  0, 15, 13],\n",
      "        [14,  1,  4,  ..., 13, 13, 13],\n",
      "        ...,\n",
      "        [14,  4,  3,  ..., 13, 13, 13],\n",
      "        [14,  4,  3,  ..., 13, 13, 13],\n",
      "        [14,  1,  5,  ..., 13, 13, 13]])\n"
     ]
    }
   ],
   "source": [
    "def print_first_batch(dataloader):\n",
    "    \"\"\"Print the first batch from dataloader.\"\"\"\n",
    "    for batch in dataloader:\n",
    "        print(\"First Batch:\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # If batch is a dictionary\n",
    "        if isinstance(batch, dict):\n",
    "            for key, value in batch.items():\n",
    "                print(f\"\\n{key}:\")\n",
    "                print(f\"  Shape: {value.shape}\")\n",
    "                print(f\"  Data: {value}\")\n",
    "        \n",
    "        # If batch is a tuple/list\n",
    "        elif isinstance(batch, (tuple, list)):\n",
    "            for i, item in enumerate(batch):\n",
    "                print(f\"\\nItem {i}:\")\n",
    "                print(f\"  Shape: {item.shape}\")\n",
    "                print(f\"  Data: {item}\")\n",
    "        \n",
    "        # If batch is a single tensor\n",
    "        else:\n",
    "            print(f\"Shape: {batch.shape}\")\n",
    "            print(f\"Data: {batch}\")\n",
    "        \n",
    "        break  # Stop after first batch\n",
    "\n",
    "print_first_batch(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d8132d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Total trainable parameters: 10,016,273\n",
      "No checkpoint found at best_diacritization_mdel.pt. Starting from scratch.\n",
      "\n",
      "Epoch 1/20\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 27/36086 [00:04<1:37:45,  6.15it/s, loss=1.84]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 36086/36086 [1:39:22<00:00,  6.05it/s, loss=0.0986]\n",
      "Evaluating: 100%|██████████| 1722/1722 [01:10<00:00, 24.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2134 | Val Loss: 0.1099\n",
      "✓ Model saved with val_loss: 0.1099\n",
      "\n",
      "Epoch 2/20\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 36086/36086 [1:39:37<00:00,  6.04it/s, loss=0.077] \n",
      "Evaluating: 100%|██████████| 1722/1722 [01:10<00:00, 24.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0920 | Val Loss: 0.0949\n",
      "✓ Model saved with val_loss: 0.0949\n",
      "\n",
      "Epoch 3/20\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 36086/36086 [1:39:45<00:00,  6.03it/s, loss=0.0715]\n",
      "Evaluating: 100%|██████████| 1722/1722 [01:10<00:00, 24.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0803 | Val Loss: 0.0890\n",
      "✓ Model saved with val_loss: 0.0890\n",
      "\n",
      "Epoch 4/20\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 36086/36086 [1:40:08<00:00,  6.01it/s, loss=0.0856]\n",
      "Evaluating: 100%|██████████| 1722/1722 [01:10<00:00, 24.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0746 | Val Loss: 0.0856\n",
      "✓ Model saved with val_loss: 0.0856\n",
      "\n",
      "Epoch 5/20\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 36086/36086 [1:40:17<00:00,  6.00it/s, loss=0.0703]\n",
      "Evaluating: 100%|██████████| 1722/1722 [01:11<00:00, 24.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0713 | Val Loss: 0.0833\n",
      "✓ Model saved with val_loss: 0.0833\n",
      "\n",
      "Epoch 6/20\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 36086/36086 [1:40:19<00:00,  5.99it/s, loss=0.05]  \n",
      "Evaluating: 100%|██████████| 1722/1722 [01:11<00:00, 24.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0695 | Val Loss: 0.0857\n",
      "\n",
      "Epoch 7/20\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  54%|█████▍    | 19661/36086 [54:34<46:52,  5.84it/s, loss=0.0837]  "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# ==================== MODEL COMPONENTS ====================\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_vocab_size, embed_size, hidden_size, num_layers, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_vocab_size, embed_size, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, \n",
    "                           batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, seq_len]\n",
    "        embedded = self.dropout(self.embedding(x))  # [batch_size, seq_len, embed_size]\n",
    "        \n",
    "        # outputs: [batch_size, seq_len, hidden_size]\n",
    "        # hidden: [num_layers, batch_size, hidden_size]\n",
    "        # cell: [num_layers, batch_size, hidden_size]\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        \n",
    "        return outputs, hidden, cell\n",
    "\n",
    "\n",
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Attention weights\n",
    "        self.W1 = nn.Linear(hidden_size, hidden_size)  # For encoder outputs\n",
    "        self.W2 = nn.Linear(hidden_size, hidden_size)  # For decoder hidden state\n",
    "        self.V = nn.Linear(hidden_size, 1)  # Final attention score\n",
    "    \n",
    "    def forward(self, encoder_outputs, decoder_hidden):\n",
    "        # encoder_outputs: [batch_size, seq_len, hidden_size]\n",
    "        # decoder_hidden: [batch_size, hidden_size]\n",
    "        \n",
    "        # Add time dimension to decoder_hidden\n",
    "        decoder_hidden = decoder_hidden.unsqueeze(1)  # [batch_size, 1, hidden_size]\n",
    "        \n",
    "        # Calculate attention scores\n",
    "        # [batch_size, seq_len, hidden_size]\n",
    "        energy = torch.tanh(self.W1(encoder_outputs) + self.W2(decoder_hidden))\n",
    "        \n",
    "        # [batch_size, seq_len, 1]\n",
    "        attention_scores = self.V(energy)\n",
    "        \n",
    "        # [batch_size, seq_len]\n",
    "        attention_weights = F.softmax(attention_scores.squeeze(2), dim=1)\n",
    "        \n",
    "        # Context vector: weighted sum of encoder outputs\n",
    "        # [batch_size, 1, seq_len] x [batch_size, seq_len, hidden_size]\n",
    "        # = [batch_size, 1, hidden_size]\n",
    "        context_vector = torch.bmm(attention_weights.unsqueeze(1), encoder_outputs)\n",
    "        \n",
    "        # [batch_size, hidden_size]\n",
    "        context_vector = context_vector.squeeze(1)\n",
    "        \n",
    "        return context_vector, attention_weights\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_vocab_size, embed_size, hidden_size, num_layers, dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_vocab_size = output_vocab_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_vocab_size, embed_size, padding_idx=0)\n",
    "        self.attention = BahdanauAttention(hidden_size)\n",
    "        \n",
    "        # LSTM input: embedding + context vector\n",
    "        self.lstm = nn.LSTM(embed_size + hidden_size, hidden_size, num_layers,\n",
    "                           batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "        \n",
    "        # Final output layer\n",
    "        self.fc = nn.Linear(hidden_size, output_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, encoder_outputs, hidden, cell):\n",
    "        # x: [batch_size, 1] - single time step\n",
    "        # encoder_outputs: [batch_size, seq_len, hidden_size]\n",
    "        # hidden: [num_layers, batch_size, hidden_size]\n",
    "        # cell: [num_layers, batch_size, hidden_size]\n",
    "        \n",
    "        # Embed input\n",
    "        embedded = self.dropout(self.embedding(x))  # [batch_size, 1, embed_size]\n",
    "        \n",
    "        # Get attention context using top decoder hidden state\n",
    "        context, attention_weights = self.attention(encoder_outputs, hidden[-1])\n",
    "        # context: [batch_size, hidden_size]\n",
    "        \n",
    "        # Concatenate embedded input and context\n",
    "        # [batch_size, 1, embed_size + hidden_size]\n",
    "        lstm_input = torch.cat([embedded, context.unsqueeze(1)], dim=2)\n",
    "        \n",
    "        # LSTM step\n",
    "        output, (hidden, cell) = self.lstm(lstm_input, (hidden, cell))\n",
    "        # output: [batch_size, 1, hidden_size]\n",
    "        \n",
    "        # Prediction\n",
    "        prediction = self.fc(output.squeeze(1))  # [batch_size, output_vocab_size]\n",
    "        \n",
    "        return prediction, hidden, cell, attention_weights\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "    \n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        # src: [batch_size, src_len]\n",
    "        # trg: [batch_size, trg_len]\n",
    "        \n",
    "        batch_size = src.shape[0]\n",
    "        trg_len = trg.shape[1]\n",
    "        trg_vocab_size = self.decoder.output_vocab_size\n",
    "        \n",
    "        # Store outputs\n",
    "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        # Encode\n",
    "        encoder_outputs, hidden, cell = self.encoder(src)\n",
    "        \n",
    "        # First input to decoder is <SOS> token (index 1)\n",
    "        decoder_input = trg[:, 0].unsqueeze(1)  # [batch_size, 1]\n",
    "        \n",
    "        # Decode\n",
    "        for t in range(1, trg_len):\n",
    "            # Get prediction\n",
    "            prediction, hidden, cell, _ = self.decoder(\n",
    "                decoder_input, encoder_outputs, hidden, cell\n",
    "            )\n",
    "            \n",
    "            # Store prediction\n",
    "            outputs[:, t] = prediction\n",
    "            \n",
    "            # Teacher forcing\n",
    "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
    "            \n",
    "            # Get next input\n",
    "            top1 = prediction.argmax(1)\n",
    "            decoder_input = trg[:, t].unsqueeze(1) if teacher_force else top1.unsqueeze(1)\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "\n",
    "# ==================== MODEL LOADING FUNCTION ====================\n",
    "\n",
    "def load_model_if_exists(model, optimizer, save_path, device):\n",
    "    \"\"\"\n",
    "    Load model checkpoint if it exists.\n",
    "    \n",
    "    Returns:\n",
    "        start_epoch: Epoch to resume training from (0 if no checkpoint)\n",
    "        best_val_loss: Best validation loss from checkpoint (inf if no checkpoint)\n",
    "    \"\"\"\n",
    "    if os.path.exists(save_path):\n",
    "        print(f\"Loading checkpoint from {save_path}...\")\n",
    "        checkpoint = torch.load(save_path, map_location=device)\n",
    "        \n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        \n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        best_val_loss = checkpoint['val_loss']\n",
    "        \n",
    "        print(f\"✓ Checkpoint loaded successfully!\")\n",
    "        print(f\"  - Resuming from epoch {start_epoch}\")\n",
    "        print(f\"  - Best validation loss: {best_val_loss:.4f}\")\n",
    "        print(f\"  - Previous train loss: {checkpoint['train_loss']:.4f}\")\n",
    "        \n",
    "        return start_epoch, best_val_loss\n",
    "    else:\n",
    "        print(f\"No checkpoint found at {save_path}. Starting from scratch.\")\n",
    "        return 0, float('inf')\n",
    "\n",
    "\n",
    "# ==================== TRAINING FUNCTION ====================\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, criterion, device, clip=1.0):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\")\n",
    "    \n",
    "    for batch_idx, batch in enumerate(progress_bar):\n",
    "        src = batch[0].to(device)  # Input (undiacritized)\n",
    "        trg = batch[1].to(device)  # Target (diacritized)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(src, trg, teacher_forcing_ratio=0.5)\n",
    "        \n",
    "        # Reshape for loss calculation\n",
    "        # output: [batch_size, trg_len, output_vocab_size]\n",
    "        # trg: [batch_size, trg_len]\n",
    "        \n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[:, 1:].reshape(-1, output_dim)  # Skip <SOS>\n",
    "        trg = trg[:, 1:].reshape(-1)\n",
    "        \n",
    "        # Calculate loss (ignore padding)\n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    return epoch_loss / len(dataloader)\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            src = batch[0].to(device)\n",
    "            trg = batch[1].to(device)\n",
    "            \n",
    "            # Turn off teacher forcing\n",
    "            output = model(src, trg, teacher_forcing_ratio=0)\n",
    "            \n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[:, 1:].reshape(-1, output_dim)\n",
    "            trg = trg[:, 1:].reshape(-1)\n",
    "            \n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "    \n",
    "    return epoch_loss / len(dataloader)\n",
    "\n",
    "\n",
    "# ==================== TRAINING LOOP ====================\n",
    "\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion, \n",
    "                device, num_epochs=10, clip=1.0, save_path='best_model.pt'):\n",
    "    \n",
    "    # Load checkpoint if exists\n",
    "    start_epoch, best_val_loss = load_model_if_exists(model, optimizer, save_path, device)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Train\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, criterion, device, clip)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Validate\n",
    "        val_loss = evaluate(model, val_loader, criterion, device)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'train_loss': train_loss,\n",
    "                'val_loss': val_loss,\n",
    "            }, 'best_diacritization_model.pt')\n",
    "            print(f\"✓ Model saved with val_loss: {val_loss:.4f}\")\n",
    "    \n",
    "    return train_losses, val_losses\n",
    "\n",
    "\n",
    "# ==================== USAGE EXAMPLE ====================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Hyperparameters (from paper)\n",
    "    INPUT_VOCAB_SIZE = vocab.vocab_size_in  # Your input vocab size\n",
    "    OUTPUT_VOCAB_SIZE = vocab.vocab_size_out  # Your output vocab size\n",
    "    EMBED_SIZE = 512\n",
    "    HIDDEN_SIZE = 512\n",
    "    NUM_LAYERS = 2\n",
    "    DROPOUT = 0.3\n",
    "    LEARNING_RATE = 0.001\n",
    "    NUM_EPOCHS = 20\n",
    "    CLIP = 1.0\n",
    "    \n",
    "    # Device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Initialize model\n",
    "    encoder = Encoder(INPUT_VOCAB_SIZE, EMBED_SIZE, HIDDEN_SIZE, NUM_LAYERS, DROPOUT)\n",
    "    decoder = Decoder(OUTPUT_VOCAB_SIZE, EMBED_SIZE, HIDDEN_SIZE, NUM_LAYERS, DROPOUT)\n",
    "    model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "    \n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total trainable parameters: {total_params:,}\")\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=13)  # Ignore padding\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    # Train (will automatically load checkpoint if exists)\n",
    "    train_losses, val_losses = train_model(\n",
    "        model, train_loader, val_loader, optimizer, criterion,\n",
    "        device, NUM_EPOCHS, CLIP, save_path='best_diacritization_model.pt'\n",
    "    )\n",
    "    \n",
    "    # Plot losses\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.savefig('training_losses.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7689f606",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val_no_window = DiacritizationDataset(val_sentences, no_diac_sentences_val, vocab)\n",
    "val_loader_no_window = DataLoader(dataset_val, batch_size=32, collate_fn=collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdce453e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_character_accuracy(model, dataloader, device):\n",
    "    \"\"\"Calculate character-level accuracy (DER - Diacritic Error Rate)\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    total_chars = 0\n",
    "    correct_chars = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Calculating Accuracy\"):\n",
    "            src = batch[0].to(device) # (batch_size,seq_length)\n",
    "            trg = batch[1].to(device) # (batch_size,seq_length)\n",
    "\n",
    "            # Get predictions (no teacher forcing)\n",
    "            output = model(src, trg, teacher_forcing_ratio=0)\n",
    "\n",
    "            # Get predicted tokens\n",
    "            predictions = output.argmax(2)  # [batch_size, seq_len]\n",
    "\n",
    "            # Compare with targets (skip <SOS> token at position 0)\n",
    "            for i in range(predictions.shape[0]):\n",
    "                pred_seq = predictions[i, 1:]  # Skip <SOS>\n",
    "                target_seq = trg[i, 1:]  # Skip <SOS>\n",
    "\n",
    "                # Only compare non-padding tokens\n",
    "                mask = target_seq != 13  # Not padding\n",
    "\n",
    "                if mask.sum() > 0:\n",
    "                    valid_preds = pred_seq[mask]\n",
    "                    valid_targets = target_seq[mask]\n",
    "                    # Count correct predictions\n",
    "                    correct_chars += (valid_preds == valid_targets).sum().item()\n",
    "                    total_chars += len(valid_targets)\n",
    "\n",
    "    accuracy = (correct_chars / total_chars) * 100 if total_chars > 0 else 0\n",
    "    error_rate = 100 - accuracy\n",
    "\n",
    "    return accuracy, error_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d28a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== LOAD MODEL AND EVALUATE ====================\n",
    "\n",
    "def load_and_evaluate(model_path, val_loader, vocab):\n",
    "    \"\"\"Load trained model and calculate accuracy metrics\"\"\"\n",
    "\n",
    "    # Hyperparameters (must match training)\n",
    "    INPUT_VOCAB_SIZE = vocab.vocab_size_in\n",
    "    OUTPUT_VOCAB_SIZE = vocab.vocab_size_out\n",
    "    EMBED_SIZE = 512\n",
    "    HIDDEN_SIZE = 512\n",
    "    NUM_LAYERS = 2\n",
    "    DROPOUT = 0.3\n",
    "\n",
    "    # Device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\\n\")\n",
    "\n",
    "    # Initialize model\n",
    "    encoder = Encoder(INPUT_VOCAB_SIZE, EMBED_SIZE, HIDDEN_SIZE, NUM_LAYERS, DROPOUT)\n",
    "    decoder = Decoder(OUTPUT_VOCAB_SIZE, EMBED_SIZE, HIDDEN_SIZE, NUM_LAYERS, DROPOUT)\n",
    "    model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "    # Load checkpoint\n",
    "    print(f\"Loading model from: {model_path}\")\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    print(f\"Model loaded successfully!\")\n",
    "    print(f\"Training epoch: {checkpoint['epoch']}\")\n",
    "    print(f\"Training loss: {checkpoint['train_loss']:.4f}\")\n",
    "    print(f\"Validation loss: {checkpoint['val_loss']:.4f}\\n\")\n",
    "\n",
    "    # Calculate metrics\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Calculating Accuracy Metrics...\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    char_accuracy, der = calculate_character_accuracy(model, val_loader, device)\n",
    "    # word_accuracy, wer = calculate_word_accuracy(model, val_loader, device)\n",
    "\n",
    "    # Print results\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"EVALUATION RESULTS\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Character Accuracy: {char_accuracy:.2f}%\")\n",
    "    print(f\"DER (Diacritic Error Rate): {der:.2f}%\")\n",
    "    # print(f\"\\nWord Accuracy: {word_accuracy:.2f}%\")\n",
    "    # print(f\"WER (Word Error Rate): {wer:.2f}%\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    return {\n",
    "        'char_accuracy': char_accuracy,\n",
    "        'der': der,\n",
    "        # 'word_accuracy': word_accuracy,\n",
    "        # 'wer': wer\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dd7744",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'best_diacritization_model.pt'\n",
    "\n",
    "# Load and evaluate\n",
    "results = load_and_evaluate(\n",
    "    model_path=model_path,\n",
    "    val_loader=val_loader_no_window,  # Your validation dataloader\n",
    "    vocab = vocab\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9116f448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentence(model, sentence, vocab, device, max_len=300):\n",
    "    \"\"\"\n",
    "    Predict diacritics for a single sentence.\n",
    "\n",
    "    Args:\n",
    "        model: Trained Seq2Seq model\n",
    "        sentence: Input sentence (without diacritics)\n",
    "        device: torch device\n",
    "        max_len: Maximum sequence length\n",
    "\n",
    "    Returns:\n",
    "        diacritized_sentence: Sentence with predicted diacritics\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    input_tokens = vocab.encode_input(sentence)\n",
    "    # Convert to tensor\n",
    "    src = torch.tensor([input_tokens]).to(device)  # [1, seq_len]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Encode\n",
    "        encoder_outputs, hidden, cell = model.encoder(src)\n",
    "\n",
    "        # Start decoding with <SOS> token\n",
    "        decoder_input = torch.tensor([[vocab.char2idx_out['<SOS>']]]).to(device) # [1,1]\n",
    "\n",
    "        predictions = []\n",
    "\n",
    "        # Decode step by step\n",
    "        for _ in range(len(input_tokens) - 2):  # -2 for <SOS> and <EOS>\n",
    "            prediction, hidden, cell, _ = model.decoder(\n",
    "                decoder_input, encoder_outputs, hidden, cell\n",
    "            )\n",
    "\n",
    "            # Get most likely token\n",
    "            top1 = prediction.argmax(1)\n",
    "            predicted_token = top1.item()\n",
    "\n",
    "            # Stop if <EOS> or <PAD>\n",
    "            if predicted_token == vocab.char2idx_out['<EOS>']:\n",
    "                print('end of the sentence')\n",
    "                break\n",
    "            predictions.append(predicted_token)\n",
    "\n",
    "            # Next input\n",
    "            decoder_input = top1.unsqueeze(0)\n",
    "\n",
    "        # Decode predictions back to text\n",
    "        # diacritized_sentence = [vocab.idx2char_out[idx] for idx in predictions]\n",
    "        diacritized_sentence = [idx for idx in predictions]\n",
    "\n",
    "\n",
    "    return diacritized_sentence\n",
    "\n",
    "def test_single_sentence(sentence, model_path, vocab):\n",
    "    \"\"\"Test a single sentence and return result\"\"\"\n",
    "\n",
    "    # Hyperparameters\n",
    "    INPUT_VOCAB_SIZE = vocab.vocab_size_in\n",
    "    OUTPUT_VOCAB_SIZE = vocab.vocab_size_out\n",
    "    EMBED_SIZE = 512\n",
    "    HIDDEN_SIZE = 512\n",
    "    NUM_LAYERS = 2\n",
    "    DROPOUT = 0.3\n",
    "\n",
    "    # Device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Load model\n",
    "    encoder = Encoder(INPUT_VOCAB_SIZE, EMBED_SIZE, HIDDEN_SIZE, NUM_LAYERS, DROPOUT)\n",
    "    decoder = Decoder(OUTPUT_VOCAB_SIZE, EMBED_SIZE, HIDDEN_SIZE, NUM_LAYERS, DROPOUT)\n",
    "    model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    sentence.replace(' ','<EOW>')\n",
    "    # Predict\n",
    "    diacritized = predict_sentence(\n",
    "        model, sentence, vocab, device\n",
    "    )\n",
    "    diacritized.reverse()\n",
    "    print(\"=\" * 60)\n",
    "    print(\"DIACRITIZATION RESULT\")\n",
    "    print(\"=\" * 60)\n",
    "    print(len(sentence))\n",
    "    print(len(diacritized))\n",
    "    print(f\"Input:  {sentence}\")\n",
    "    print(f\"Output: {diacritized}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    return diacritized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d1e762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path, vocab):\n",
    "    \"\"\"Load trained model and calculate accuracy metrics\"\"\"\n",
    "\n",
    "    # Hyperparameters (must match training)\n",
    "    INPUT_VOCAB_SIZE = vocab.vocab_size_in\n",
    "    OUTPUT_VOCAB_SIZE = vocab.vocab_size_out\n",
    "    EMBED_SIZE = 512\n",
    "    HIDDEN_SIZE = 512\n",
    "    NUM_LAYERS = 2\n",
    "    DROPOUT = 0.3\n",
    "\n",
    "    # Device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\\n\")\n",
    "\n",
    "    # Initialize model\n",
    "    encoder = Encoder(INPUT_VOCAB_SIZE, EMBED_SIZE, HIDDEN_SIZE, NUM_LAYERS, DROPOUT)\n",
    "    decoder = Decoder(OUTPUT_VOCAB_SIZE, EMBED_SIZE, HIDDEN_SIZE, NUM_LAYERS, DROPOUT)\n",
    "    model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "    # Load checkpoint\n",
    "    print(f\"Loading model from: {model_path}\")\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    print(f\"Model loaded successfully!\")\n",
    "    print(f\"Training epoch: {checkpoint['epoch']}\")\n",
    "    print(f\"Training loss: {checkpoint['train_loss']:.4f}\")\n",
    "    print(f\"Validation loss: {checkpoint['val_loss']:.4f}\\n\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a489d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sliding_windows(sentence, window_size=3):\n",
    "    \"\"\"\n",
    "    Create sliding windows of consecutive words from a sentence.\n",
    "    For sentence \"w1 w2 w3 w4 w5\" with window_size=3:\n",
    "    Returns: [\"w1 w2 w3\", \"w2 w3 w4\", \"w3 w4 w5\"]\n",
    "    Also returns the word lengths for each window.\n",
    "    \"\"\"\n",
    "    words = sentence.split()\n",
    "    windows = [] \n",
    "    window_word_lengths = []  # Store character lengths of words in each window\n",
    "\n",
    "    if len(words) <= window_size:\n",
    "        # If sentence is shorter than or equal to window size, return entire sentence\n",
    "        word_lengths = [len(word) for word in words]\n",
    "        return [sentence], [word_lengths]\n",
    "\n",
    "    # Create sliding windows\n",
    "    for i in range(len(words) - window_size + 1):\n",
    "        window_words = words[i:i + window_size]\n",
    "        window = ' '.join(window_words)\n",
    "        windows.append(window)\n",
    "\n",
    "        # Store the character length of each word in this window\n",
    "        word_lengths = [len(word) for word in window_words]\n",
    "        window_word_lengths.append(word_lengths)\n",
    "    print(word_lengths)\n",
    "    return windows, window_word_lengths\n",
    "\n",
    "\n",
    "def predict_window(model, window_text, word_lengths,vocab, device):\n",
    "    \"\"\"\n",
    "    Predict diacritics for a single window.\n",
    "    Returns list of predicted words with diacritics.\n",
    "\n",
    "    Args:\n",
    "        model: Trained Seq2Seq model\n",
    "        window_text: String of words in the window (without diacritics)\n",
    "        word_lengths: List of character lengths for each word in window\n",
    "        vocab_input: Input vocabulary list\n",
    "        vocab_output: Output vocabulary list\n",
    "        device: torch device\n",
    "\n",
    "    Returns:\n",
    "        List of predicted words with diacritics\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    input_tokens = vocab.encode_input(window_text)\n",
    "\n",
    "    src = torch.tensor([input_tokens]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Encode\n",
    "        encoder_outputs, hidden, cell = model.encoder(src)\n",
    "\n",
    "        # Start decoding\n",
    "        sos_idx = vocab.char2idx_out['<SOS>']\n",
    "        decoder_input = torch.tensor([[sos_idx]]).to(device) # (1,1)\n",
    "\n",
    "        predictions = []\n",
    "        eos_idx = vocab.char2idx_out['<EOS>']\n",
    "\n",
    "        # Predict characters (output will have diacritics, so potentially longer)\n",
    "        # max_length = len(input_text_no_spaces) * 3\n",
    "\n",
    "        for step in range(len(input_tokens) - 2):\n",
    "            prediction, hidden, cell, _ = model.decoder(\n",
    "                decoder_input, encoder_outputs, hidden, cell\n",
    "            )\n",
    "\n",
    "            top1 = prediction.argmax(1)\n",
    "            predicted_token = top1.item()\n",
    "\n",
    "            # Check for EOS token\n",
    "            if predicted_token == eos_idx:\n",
    "                break\n",
    "\n",
    "            predictions.append(predicted_token)\n",
    "            decoder_input = top1.unsqueeze(0)\n",
    "\n",
    "        # Decode to text (continuous string with diacritics, no spaces)\n",
    "        diacritized_text = predictions\n",
    "        # diacritized_text = [vocab.idx2char_out.get(idx, '') for idx in predictions]\n",
    "\n",
    "        # Clean up tokens\n",
    "        # diacritized_text = [' ' if c == '<EOW>' else c for c in diacritized_text]\n",
    "\n",
    "    # Now split the predicted text into words using the original word lengths\n",
    "    print(f\"Predicted diacritized text tokens: {diacritized_text}\")\n",
    "    predicted_words = []\n",
    "    char_idx = 0\n",
    "    for word_len in word_lengths:\n",
    "        # For each original word, we need to extract characters from predicted text\n",
    "        # The predicted text has diacritics, so we need to count base characters\n",
    "\n",
    "        word_diacritics = []\n",
    "        for _ in range(word_len):\n",
    "            word_diacritics.append(diacritized_text[char_idx])\n",
    "            char_idx += 1\n",
    "        word_diacritics\n",
    "        char_idx += 1 # for space\n",
    "        predicted_words.append(word_diacritics)\n",
    "\n",
    "    predicted_words\n",
    "    return predicted_words\n",
    "\n",
    "\n",
    "def predict_sentence_with_voting(model, sentence, vocab, device, window_size=9):\n",
    "    model.eval()\n",
    "\n",
    "    # Step 1: Split into words and store lengths\n",
    "    words = sentence.split()\n",
    "    num_words = len(words)\n",
    "    word_lengths = [len(word) for word in words]\n",
    "\n",
    "    if num_words == 0:\n",
    "        return \"\"\n",
    "\n",
    "    print(f\"Input: {num_words} words\")\n",
    "    print(f\"Word lengths: {word_lengths}\")\n",
    "    print(f\"Words: {words}\")\n",
    "    print()\n",
    "\n",
    "    # Handle short sentences\n",
    "    if num_words <= window_size:\n",
    "        print(f\"Sentence has {num_words} words, window size is {window_size}\")\n",
    "        print(\"Processing entire sentence as one window\")\n",
    "        try:\n",
    "            predicted_words = predict_window(model, sentence, word_lengths, vocab, device)\n",
    "        except Exception as e:\n",
    "            print(f\"Error predicting sentence: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return sentence\n",
    "\n",
    "    # Step 2: Create sliding windows\n",
    "    windows, window_word_lengths = create_sliding_windows(sentence, window_size)\n",
    "\n",
    "    print(f\"Created {len(windows)} windows\\n\")\n",
    "\n",
    "    # Step 3: Collect predictions\n",
    "    word_predictions = [[] for _ in range(num_words)]\n",
    "\n",
    "    for window_idx, (window, w_lengths) in enumerate(zip(windows, window_word_lengths)):\n",
    "        try:\n",
    "            print(f\"Window {window_idx}: {window}\")\n",
    "\n",
    "            predicted_words = predict_window(model, window, w_lengths, vocab, device)\n",
    "            print(f\"Predicted words: {predicted_words}\")\n",
    "\n",
    "            window_start_idx = window_idx\n",
    "\n",
    "            for i, pred_word in enumerate(predicted_words):\n",
    "                actual_idx = window_start_idx + i\n",
    "                if 0 <= actual_idx < num_words:\n",
    "                    # Keep pred_word as LIST OF DIACRITICS (not string)\n",
    "                    word_predictions[actual_idx].append(pred_word)\n",
    "                    print(f\"  -> Stored for word {actual_idx}\")\n",
    "\n",
    "            print()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in window {window_idx}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            window_start_idx = window_idx\n",
    "            for i in range(min(window_size, num_words - window_idx)):\n",
    "                actual_idx = window_start_idx + i\n",
    "                if 0 <= actual_idx < num_words:\n",
    "                    word_predictions[actual_idx].append(list(words[actual_idx]))\n",
    "\n",
    "    # Step 4: Voting (modified)\n",
    "    final_words = []\n",
    "\n",
    "    print(\"=\"*60)\n",
    "    print(\"VOTING RESULTS:\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    from collections import Counter\n",
    "\n",
    "    for word_idx, predictions in enumerate(word_predictions):\n",
    "        if len(predictions) == 0:\n",
    "            print(f\"Word {word_idx} ({words[word_idx]}): No predictions -> using original\")\n",
    "            final_words.append(list(words[word_idx]))\n",
    "            continue\n",
    "\n",
    "        if len(predictions) == 1:\n",
    "            print(f\"Word {word_idx} ({words[word_idx]}): 1 prediction -> {predictions[0]}\")\n",
    "            final_words.append(predictions[0])\n",
    "            continue\n",
    "\n",
    "        # --- Character-level voting ---\n",
    "        word_len = len(words[word_idx])\n",
    "        final_word = []\n",
    "\n",
    "        for pos in range(word_len):\n",
    "            chars_at_pos = []\n",
    "            for pred in predictions:\n",
    "                if len(pred) > pos:\n",
    "                    chars_at_pos.append(pred[pos])\n",
    "\n",
    "            if len(chars_at_pos) > 0:\n",
    "                best_char = Counter(chars_at_pos).most_common(1)[0][0]\n",
    "            else:\n",
    "                # fallback: use original character (no diacritic)\n",
    "                best_char = words[word_idx][pos]\n",
    "\n",
    "            final_word.append(best_char)\n",
    "\n",
    "        print(f\"Word {word_idx} ({words[word_idx]}): {len(predictions)} predictions -> {final_word}\")\n",
    "        final_words.append(final_word)\n",
    "\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    return final_words\n",
    "\n",
    "\n",
    "\n",
    "# Expected behavior for 5 words with window_size=3:\n",
    "# Window 0: w0 w1 w2 -> predictions for words 0, 1, 2\n",
    "# Window 1: w1 w2 w3 -> predictions for words 1, 2, 3\n",
    "# Window 2: w2 w3 w4 -> predictions for words 2, 3, 4\n",
    "#\n",
    "# Voting:\n",
    "# word_predictions[0] = [pred from window 0] -> 1 prediction\n",
    "# word_predictions[1] = [pred from window 0, pred from window 1] -> 2 predictions (vote)\n",
    "# word_predictions[2] = [pred from window 0, pred from window 1, pred from window 2] -> 3 predictions (vote)\n",
    "# word_predictions[3] = [pred from window 1, pred from window 2] -> 2 predictions (vote)\n",
    "# word_predictions[4] = [pred from window 2] -> 1 prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e910e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'best_diacritization_model.pt'\n",
    "model = load_model(model_path,vocab)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c50867f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_words = predict_sentence_with_voting(model,'ذهبت الى الحديقة مع اصدقاء السوء لتركب العجلة',vocab,device,window_size=5)\n",
    "final_words_reversed = [] \n",
    "for word in final_words:\n",
    "    word.reverse()\n",
    "    final_words_reversed.append(word)\n",
    "final_words_reversed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c4903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_last_character_accuracy(model, dataloader, device):\n",
    "    \"\"\"Calculate accuracy for the last character of each word (before EOW token)\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    total_last_chars = 0\n",
    "    correct_last_chars = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Calculating Last Char Accuracy\"):\n",
    "            src = batch[0].to(device)  # (batch_size, seq_length)\n",
    "            trg = batch[1].to(device)  # (batch_size, seq_length)\n",
    "\n",
    "            # Get predictions (no teacher forcing)\n",
    "            output = model(src, trg, teacher_forcing_ratio=0)\n",
    "\n",
    "            # Get predicted tokens\n",
    "            predictions = output.argmax(2)  # [batch_size, seq_len]\n",
    "\n",
    "            # Compare with targets (skip <SOS> token at position 0)\n",
    "            for i in range(predictions.shape[0]):\n",
    "                pred_seq = predictions[i, 1:]  # Skip <SOS>\n",
    "                target_seq = trg[i, 1:]  # Skip <SOS>\n",
    "\n",
    "                # Find positions of EOW tokens (index 12)\n",
    "                eow_positions = (target_seq == 12).nonzero(as_tuple=True)[0]\n",
    "\n",
    "                # For each EOW, check the character right before it\n",
    "                for eow_pos in eow_positions:\n",
    "                    if eow_pos > 0:  # Make sure there's a character before EOW\n",
    "                        last_char_pos = eow_pos - 1\n",
    "                        \n",
    "                        # Skip if it's a padding token\n",
    "                        if target_seq[last_char_pos] != 13:\n",
    "                            pred_last_char = pred_seq[last_char_pos]\n",
    "                            target_last_char = target_seq[last_char_pos]\n",
    "                            \n",
    "                            # Check if prediction matches target\n",
    "                            if pred_last_char == target_last_char:\n",
    "                                correct_last_chars += 1\n",
    "                            \n",
    "                            total_last_chars += 1\n",
    "\n",
    "    accuracy = (correct_last_chars / total_last_chars) * 100 if total_last_chars > 0 else 0\n",
    "    error_rate = 100 - accuracy\n",
    "\n",
    "    return accuracy, error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf8ea9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== LOAD MODEL AND EVALUATE ====================\n",
    "\n",
    "def load_and_evaluate_last_char(model_path, val_loader, vocab):\n",
    "    \"\"\"Load trained model and calculate accuracy metrics\"\"\"\n",
    "\n",
    "    # Hyperparameters (must match training)\n",
    "    INPUT_VOCAB_SIZE = vocab.vocab_size_in\n",
    "    OUTPUT_VOCAB_SIZE = vocab.vocab_size_out\n",
    "    EMBED_SIZE = 512\n",
    "    HIDDEN_SIZE = 512\n",
    "    NUM_LAYERS = 2\n",
    "    DROPOUT = 0.3\n",
    "\n",
    "    # Device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\\n\")\n",
    "\n",
    "    # Initialize model\n",
    "    encoder = Encoder(INPUT_VOCAB_SIZE, EMBED_SIZE, HIDDEN_SIZE, NUM_LAYERS, DROPOUT)\n",
    "    decoder = Decoder(OUTPUT_VOCAB_SIZE, EMBED_SIZE, HIDDEN_SIZE, NUM_LAYERS, DROPOUT)\n",
    "    model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "    # Load checkpoint\n",
    "    print(f\"Loading model from: {model_path}\")\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    print(f\"Model loaded successfully!\")\n",
    "    print(f\"Training epoch: {checkpoint['epoch']}\")\n",
    "    print(f\"Training loss: {checkpoint['train_loss']:.4f}\")\n",
    "    print(f\"Validation loss: {checkpoint['val_loss']:.4f}\\n\")\n",
    "\n",
    "    # Calculate metrics\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Calculating Accuracy Metrics...\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    char_accuracy, der = calculate_last_character_accuracy(model, val_loader, device)\n",
    "    # word_accuracy, wer = calculate_word_accuracy(model, val_loader, device)\n",
    "\n",
    "    # Print results\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"EVALUATION RESULTS\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Character Accuracy: {char_accuracy:.2f}%\")\n",
    "    print(f\"DER (Diacritic Error Rate): {der:.2f}%\")\n",
    "    # print(f\"\\nWord Accuracy: {word_accuracy:.2f}%\")\n",
    "    # print(f\"WER (Word Error Rate): {wer:.2f}%\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    return {\n",
    "        'char_accuracy': char_accuracy,\n",
    "        'der': der,\n",
    "        # 'word_accuracy': word_accuracy,\n",
    "        # 'wer': wer\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c26d793",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'best_diacritization_model.pt'\n",
    "\n",
    "# Load and evaluate\n",
    "results = load_and_evaluate_last_char(\n",
    "    model_path=model_path,\n",
    "    val_loader=val_loader_no_window,  # Your validation dataloader\n",
    "    vocab = vocab\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
