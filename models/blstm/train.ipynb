{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab90ba66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root added to path: /home/mohamed-ashraf/Desktop/projects/Arabic-Diacritization\n",
      "Current working directory: /home/mohamed-ashraf/Desktop/projects/Arabic-Diacritization/models/blstm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent.parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"Project root added to path: {project_root}\")\n",
    "print(f\"Current working directory: {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58284479",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T18:35:01.384815Z",
     "iopub.status.busy": "2025-12-03T18:35:01.384535Z",
     "iopub.status.idle": "2025-12-03T18:35:03.125782Z",
     "shell.execute_reply": "2025-12-03T18:35:03.124981Z",
     "shell.execute_reply.started": "2025-12-03T18:35:01.384794Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from utils.utils import create_data_pipeline\n",
    "from models.blstm.blstm import BLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44d41ed1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T18:35:03.132389Z",
     "iopub.status.busy": "2025-12-03T18:35:03.132173Z",
     "iopub.status.idle": "2025-12-03T18:35:03.215577Z",
     "shell.execute_reply": "2025-12-03T18:35:03.214692Z",
     "shell.execute_reply.started": "2025-12-03T18:35:03.132372Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "821762c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T18:35:03.217880Z",
     "iopub.status.busy": "2025-12-03T18:35:03.217643Z",
     "iopub.status.idle": "2025-12-03T18:35:03.232767Z",
     "shell.execute_reply": "2025-12-03T18:35:03.232005Z",
     "shell.execute_reply.started": "2025-12-03T18:35:03.217861Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ظ': 0, 'ي': 1, 'غ': 2, 'ن': 3, 'ق': 4, 'ذ': 5, 'د': 6, 'خ': 7, 'ر': 8, 'ط': 9, 'ى': 10, 'م': 11, 'ل': 12, '<PAD>': 13, 'ت': 14, 'ج': 15, 'آ': 16, 'ا': 17, 'س': 18, 'ئ': 19, 'ع': 20, 'ف': 21, 'ص': 22, 'ه': 23, 'ز': 24, 'ك': 25, 'ش': 26, 'أ': 27, 'و': 28, 'ب': 29, 'ؤ': 30, 'ض': 31, 'ة': 32, 'ث': 33, 'ء': 34, 'ح': 35, 'إ': 36, ' ': 37}\n",
      "{0: 'ظ', 1: 'ي', 2: 'غ', 3: 'ن', 4: 'ق', 5: 'ذ', 6: 'د', 7: 'خ', 8: 'ر', 9: 'ط', 10: 'ى', 11: 'م', 12: 'ل', 13: '<PAD>', 14: 'ت', 15: 'ج', 16: 'آ', 17: 'ا', 18: 'س', 19: 'ئ', 20: 'ع', 21: 'ف', 22: 'ص', 23: 'ه', 24: 'ز', 25: 'ك', 26: 'ش', 27: 'أ', 28: 'و', 29: 'ب', 30: 'ؤ', 31: 'ض', 32: 'ة', 33: 'ث', 34: 'ء', 35: 'ح', 36: 'إ', 37: ' '}\n",
      "{'َ': 0, 'ً': 1, 'ُ': 2, 'ٌ': 3, 'ِ': 4, 'ٍ': 5, 'ْ': 6, 'ّ': 7, 'َّ': 8, 'ًّ': 9, 'ُّ': 10, 'ٌّ': 11, 'ِّ': 12, 'ٍّ': 13, '': 14, '<PAD>': 15}\n",
      "{0: 'َ', 1: 'ً', 2: 'ُ', 3: 'ٌ', 4: 'ِ', 5: 'ٍ', 6: 'ْ', 7: 'ّ', 8: 'َّ', 9: 'ًّ', 10: 'ُّ', 11: 'ٌّ', 12: 'ِّ', 13: 'ٍّ', 14: '', 15: '<PAD>'}\n"
     ]
    }
   ],
   "source": [
    "with open(project_root / \"utils/letter2idx.pickle\", \"rb\") as file:\n",
    "    letter2idx = pickle.load(file)\n",
    "\n",
    "with open(project_root / \"utils/diacritic2id.pickle\", \"rb\") as file:\n",
    "    diacritic2id = pickle.load(file)\n",
    "\n",
    "idx2letter = {value: key for key, value in letter2idx.items()}\n",
    "idx2diacritic = {value: key for key, value in diacritic2id.items()}\n",
    "\n",
    "print(letter2idx)\n",
    "print(idx2letter)\n",
    "print(diacritic2id)\n",
    "print(idx2diacritic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c315df86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T18:35:03.233822Z",
     "iopub.status.busy": "2025-12-03T18:35:03.233604Z",
     "iopub.status.idle": "2025-12-03T18:35:03.251725Z",
     "shell.execute_reply": "2025-12-03T18:35:03.250780Z",
     "shell.execute_reply.started": "2025-12-03T18:35:03.233804Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 38\n",
      "Num classes: 16\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(letter2idx) \n",
    "num_classes = len(diacritic2id)\n",
    "print(\"Vocab size:\", vocab_size)\n",
    "print(\"Num classes:\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff100b0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T20:08:59.250442Z",
     "iopub.status.busy": "2025-12-03T20:08:59.250084Z",
     "iopub.status.idle": "2025-12-03T20:08:59.264207Z",
     "shell.execute_reply": "2025-12-03T20:08:59.263618Z",
     "shell.execute_reply.started": "2025-12-03T20:08:59.250405Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, epochs=10, learning_rate=0.0001):\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=diacritic2id['<PAD>'])\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5)\n",
    "    \n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_model_path = 'best_lstm_model.pth'\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        total_train_loss = 0\n",
    "        total_train_correct = 0\n",
    "        total_train_tokens = 0\n",
    "\n",
    "        with tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs} [Train]') as pbar:\n",
    "            for batch_X, batch_y, _, lengths in pbar:\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(batch_X, lengths)\n",
    "\n",
    "                B, T, C = outputs.shape\n",
    "                loss = criterion(outputs.view(B*T, C), batch_y.view(B*T))\n",
    "\n",
    "                preds = outputs.argmax(dim=-1)\n",
    "                mask = (batch_y != diacritic2id['<PAD>'])\n",
    "\n",
    "                correct = (preds[mask] == batch_y[mask]).sum().item()\n",
    "                total = mask.sum().item()\n",
    "\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "\n",
    "                total_train_loss += loss.item()\n",
    "                total_train_correct += correct\n",
    "                total_train_tokens += total\n",
    "\n",
    "                acc = correct / total if total > 0 else 0.0\n",
    "\n",
    "                pbar.set_postfix({\n",
    "                    'Loss': f'{loss.item():.4f}',\n",
    "                    'Acc': f'{acc:.4f}'\n",
    "                })\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        avg_train_acc = total_train_correct / total_train_tokens\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        total_val_correct = 0\n",
    "        total_val_tokens = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            with tqdm(val_loader, desc=f'Epoch {epoch+1}/{epochs} [Val]') as pbar:\n",
    "                for batch_X, batch_y, _, lengths in pbar:\n",
    "                    batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "                    outputs = model(batch_X, lengths)\n",
    "                    B, T, C = outputs.shape\n",
    "\n",
    "                    loss = criterion(outputs.view(B*T, C), batch_y.view(B*T))\n",
    "\n",
    "                    preds = outputs.argmax(dim=-1)\n",
    "                    mask = (batch_y != diacritic2id['<PAD>'])\n",
    "\n",
    "                    correct = (preds[mask] == batch_y[mask]).sum().item()\n",
    "                    total = mask.sum().item()\n",
    "\n",
    "                    total_val_loss += loss.item()\n",
    "                    total_val_correct += correct\n",
    "                    total_val_tokens += total\n",
    "\n",
    "                    acc = correct / total if total > 0 else 0.0\n",
    "\n",
    "                    pbar.set_postfix({\n",
    "                        'Loss': f'{loss.item():.4f}',\n",
    "                        'Acc': f'{acc:.4f}'\n",
    "                    })\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        avg_val_acc = total_val_correct / total_val_tokens\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': best_val_loss,\n",
    "                'val_accuracy': avg_val_acc,\n",
    "                'train_loss': avg_train_loss,\n",
    "                'train_accuracy': avg_train_acc\n",
    "            }, best_model_path)\n",
    "            print(f\"  ↳ Best model saved! (val_loss: {best_val_loss:.4f})\")\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{epochs}:')\n",
    "        print(f'  Train Loss: {avg_train_loss:.4f}, Train Acc: {avg_train_acc:.4f}')\n",
    "        print(f'  Val Loss: {avg_val_loss:.4f}, Val Acc: {avg_val_acc:.4f}')\n",
    "        print(f'  LR: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "\n",
    "        train_losses.append(avg_train_loss)\n",
    "        train_accuracies.append(avg_train_acc)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        val_accuracies.append(avg_val_acc)\n",
    "\n",
    "    return {\n",
    "        'train_loss': train_losses,\n",
    "        'train_accuracy': train_accuracies,\n",
    "        'val_loss': val_losses,\n",
    "        'val_accuracy': val_accuracies\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b236a82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T18:35:03.926150Z",
     "iopub.status.busy": "2025-12-03T18:35:03.925933Z",
     "iopub.status.idle": "2025-12-03T18:35:03.952518Z",
     "shell.execute_reply": "2025-12-03T18:35:03.951601Z",
     "shell.execute_reply.started": "2025-12-03T18:35:03.926130Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def pad_collate_fn(batch):\n",
    "    x_batch, y_batch, mask_batch = zip(*batch)\n",
    "    lengths_x = [len(x) for x in x_batch]\n",
    "    x_padded = torch.nn.utils.rnn.pad_sequence(x_batch, batch_first=True, padding_value=letter2idx['<PAD>'])\n",
    "    y_padded = torch.nn.utils.rnn.pad_sequence(y_batch, batch_first=True, padding_value=diacritic2id['<PAD>'])\n",
    "    mask_spadded = torch.nn.utils.rnn.pad_sequence(mask_batch, batch_first=True, padding_value=0)\n",
    "    return x_padded, y_padded, mask_spadded, torch.tensor(lengths_x, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11220db5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T18:35:03.997611Z",
     "iopub.status.busy": "2025-12-03T18:35:03.997378Z",
     "iopub.status.idle": "2025-12-03T18:35:04.022303Z",
     "shell.execute_reply": "2025-12-03T18:35:04.021708Z",
     "shell.execute_reply.started": "2025-12-03T18:35:03.997594Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset, train_loader = create_data_pipeline(\n",
    "    corpus_path=str(project_root / 'data/train.txt'), \n",
    "    letter2idx=letter2idx, \n",
    "    diacritic2idx=diacritic2id, \n",
    "    collate_fn=pad_collate_fn,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "val_dataset, val_loader = create_data_pipeline(\n",
    "    corpus_path=str(project_root / 'data/val.txt'), \n",
    "    letter2idx=letter2idx, \n",
    "    diacritic2idx=diacritic2id,\n",
    "    collate_fn=pad_collate_fn,\n",
    "    train=False, \n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92527ce6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T20:07:21.048636Z",
     "iopub.status.busy": "2025-12-03T20:07:21.047789Z",
     "iopub.status.idle": "2025-12-03T20:07:21.067300Z",
     "shell.execute_reply": "2025-12-03T20:07:21.066404Z",
     "shell.execute_reply.started": "2025-12-03T20:07:21.048584Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture:\n",
      "BLSTM(\n",
      "  (embedding): Embedding(38, 128, padding_idx=13)\n",
      "  (bilstm): LSTM(128, 256, batch_first=True, bidirectional=True)\n",
      "  (fc): Linear(in_features=512, out_features=16, bias=True)\n",
      ")\n",
      "\n",
      "Total parameters: 803,600\n",
      "Trainable parameters: 803,600\n"
     ]
    }
   ],
   "source": [
    "model = BLSTM(vocab_size=vocab_size, num_classes=num_classes).to(device)\n",
    "\n",
    "print(\"Model architecture:\")\n",
    "print(model)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6cc0df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T20:09:04.336716Z",
     "iopub.status.busy": "2025-12-03T20:09:04.336006Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nModel Summary:\n",
      "Total parameters: 803,600\n",
      "\\nStarting training with dynamic sequence lengths...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 5784/5784 [10:47<00:00,  8.94it/s, Loss=0.1161, Acc=0.9652]\n",
      "Epoch 1/10 [Val]: 100%|██████████| 282/282 [00:14<00:00, 19.87it/s, Loss=0.0943, Acc=0.9717]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ Best model saved! (val_loss: 0.1055)\n",
      "Epoch 1/10:\n",
      "  Train Loss: 0.0933, Train Acc: 0.9706\n",
      "  Val Loss: 0.1055, Val Acc: 0.9673\n",
      "  LR: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 5784/5784 [10:46<00:00,  8.94it/s, Loss=0.0681, Acc=0.9766]\n",
      "Epoch 2/10 [Val]: 100%|██████████| 282/282 [00:14<00:00, 19.96it/s, Loss=0.0964, Acc=0.9717]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ Best model saved! (val_loss: 0.1045)\n",
      "Epoch 2/10:\n",
      "  Train Loss: 0.0887, Train Acc: 0.9721\n",
      "  Val Loss: 0.1045, Val Acc: 0.9677\n",
      "  LR: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 5784/5784 [10:46<00:00,  8.95it/s, Loss=0.0756, Acc=0.9652]\n",
      "Epoch 3/10 [Val]: 100%|██████████| 282/282 [00:14<00:00, 19.92it/s, Loss=0.0888, Acc=0.9717]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ Best model saved! (val_loss: 0.1042)\n",
      "Epoch 3/10:\n",
      "  Train Loss: 0.0868, Train Acc: 0.9727\n",
      "  Val Loss: 0.1042, Val Acc: 0.9679\n",
      "  LR: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 5784/5784 [10:52<00:00,  8.86it/s, Loss=0.1235, Acc=0.9679]\n",
      "Epoch 4/10 [Val]: 100%|██████████| 282/282 [00:14<00:00, 19.51it/s, Loss=0.0875, Acc=0.9717]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ Best model saved! (val_loss: 0.1036)\n",
      "Epoch 4/10:\n",
      "  Train Loss: 0.0853, Train Acc: 0.9732\n",
      "  Val Loss: 0.1036, Val Acc: 0.9682\n",
      "  LR: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|██████████| 5784/5784 [10:54<00:00,  8.84it/s, Loss=0.0543, Acc=0.9827]\n",
      "Epoch 5/10 [Val]: 100%|██████████| 282/282 [00:14<00:00, 19.52it/s, Loss=0.0866, Acc=0.9717]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ Best model saved! (val_loss: 0.1034)\n",
      "Epoch 5/10:\n",
      "  Train Loss: 0.0840, Train Acc: 0.9736\n",
      "  Val Loss: 0.1034, Val Acc: 0.9682\n",
      "  LR: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Train]: 100%|██████████| 5784/5784 [10:54<00:00,  8.84it/s, Loss=0.1283, Acc=0.9594]\n",
      "Epoch 6/10 [Val]: 100%|██████████| 282/282 [00:14<00:00, 19.53it/s, Loss=0.0812, Acc=0.9753]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ Best model saved! (val_loss: 0.1031)\n",
      "Epoch 6/10:\n",
      "  Train Loss: 0.0827, Train Acc: 0.9740\n",
      "  Val Loss: 0.1031, Val Acc: 0.9683\n",
      "  LR: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 [Train]:  56%|█████▌    | 3213/5784 [06:04<04:47,  8.93it/s, Loss=0.0828, Acc=0.9718]"
     ]
    }
   ],
   "source": [
    "print(\"Model Summary:\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "history = train_model(model, train_loader, val_loader, epochs=10)\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_accuracy'], label='Training Accuracy')\n",
    "plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_loss'], label='Training Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save model\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'vocab_size': vocab_size,\n",
    "    'num_classes': num_classes,\n",
    "    'history': history\n",
    "}, 'blstm_model.pth')\n",
    "\n",
    "print(\"Model saved successfully as 'blstm_model.pth'!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
