{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e7e7eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root added to path: /home/mohamed-ashraf/Desktop/projects/Arabic-Diacritization\n",
      "Current working directory: /home/mohamed-ashraf/Desktop/projects/Arabic-Diacritization/models/mohamed_ashraf\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent.parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"Project root added to path: {project_root}\")\n",
    "print(f\"Current working directory: {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58284479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from utils.utils import create_data_pipeline\n",
    "from models.mohamed_ashraf.bilstm3 import BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44d41ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "821762c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ÿ∏': 0, 'Ÿä': 1, 'ÿ∫': 2, 'ŸÜ': 3, 'ŸÇ': 4, 'ÿ∞': 5, 'ÿØ': 6, 'ÿÆ': 7, 'ÿ±': 8, 'ÿ∑': 9, 'Ÿâ': 10, 'ŸÖ': 11, 'ŸÑ': 12, '<PAD>': 13, 'ÿ™': 14, 'ÿ¨': 15, 'ÿ¢': 16, 'ÿß': 17, 'ÿ≥': 18, 'ÿ¶': 19, 'ÿπ': 20, 'ŸÅ': 21, 'ÿµ': 22, 'Ÿá': 23, 'ÿ≤': 24, 'ŸÉ': 25, 'ÿ¥': 26, 'ÿ£': 27, 'Ÿà': 28, 'ÿ®': 29, 'ÿ§': 30, 'ÿ∂': 31, 'ÿ©': 32, 'ÿ´': 33, 'ÿ°': 34, 'ÿ≠': 35, 'ÿ•': 36, ' ': 37}\n",
      "{0: 'ÿ∏', 1: 'Ÿä', 2: 'ÿ∫', 3: 'ŸÜ', 4: 'ŸÇ', 5: 'ÿ∞', 6: 'ÿØ', 7: 'ÿÆ', 8: 'ÿ±', 9: 'ÿ∑', 10: 'Ÿâ', 11: 'ŸÖ', 12: 'ŸÑ', 13: '<PAD>', 14: 'ÿ™', 15: 'ÿ¨', 16: 'ÿ¢', 17: 'ÿß', 18: 'ÿ≥', 19: 'ÿ¶', 20: 'ÿπ', 21: 'ŸÅ', 22: 'ÿµ', 23: 'Ÿá', 24: 'ÿ≤', 25: 'ŸÉ', 26: 'ÿ¥', 27: 'ÿ£', 28: 'Ÿà', 29: 'ÿ®', 30: 'ÿ§', 31: 'ÿ∂', 32: 'ÿ©', 33: 'ÿ´', 34: 'ÿ°', 35: 'ÿ≠', 36: 'ÿ•', 37: ' '}\n",
      "{'Ÿé': 0, 'Ÿã': 1, 'Ÿè': 2, 'Ÿå': 3, 'Ÿê': 4, 'Ÿç': 5, 'Ÿí': 6, 'Ÿë': 7, 'ŸëŸé': 8, 'ŸëŸã': 9, 'ŸëŸè': 10, 'ŸëŸå': 11, 'ŸëŸê': 12, 'ŸëŸç': 13, '': 14, '<PAD>': 15}\n",
      "{0: 'Ÿé', 1: 'Ÿã', 2: 'Ÿè', 3: 'Ÿå', 4: 'Ÿê', 5: 'Ÿç', 6: 'Ÿí', 7: 'Ÿë', 8: 'ŸëŸé', 9: 'ŸëŸã', 10: 'ŸëŸè', 11: 'ŸëŸå', 12: 'ŸëŸê', 13: 'ŸëŸç', 14: '', 15: '<PAD>'}\n"
     ]
    }
   ],
   "source": [
    "with open(project_root / \"utils/letter2idx.pickle\", \"rb\") as file:\n",
    "    letter2idx = pickle.load(file)\n",
    "\n",
    "with open(project_root / \"utils/diacritic2id.pickle\", \"rb\") as file:\n",
    "    diacritic2id = pickle.load(file)\n",
    "\n",
    "idx2letter = {value: key for key, value in letter2idx.items()}\n",
    "idx2diacritic = {value: key for key, value in diacritic2id.items()}\n",
    "\n",
    "print(letter2idx)\n",
    "print(idx2letter)\n",
    "print(diacritic2id)\n",
    "print(idx2diacritic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c315df86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 38\n",
      "Num classes: 16\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(letter2idx) \n",
    "num_classes = len(diacritic2id)\n",
    "print(\"Vocab size:\", vocab_size)\n",
    "print(\"Num classes:\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff100b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, epochs=10, learning_rate=0.001):\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=diacritic2id['<PAD>'])\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5)\n",
    "    \n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_model_path = 'best_bilstm_model.pth'\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        total_train_loss = 0\n",
    "        total_train_correct = 0\n",
    "        total_train_tokens = 0\n",
    "\n",
    "        with tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs} [Train]') as pbar:\n",
    "            for batch_X, batch_y, _, lengths in pbar:\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(batch_X, lengths)\n",
    "\n",
    "                B, T, C = outputs.shape\n",
    "                loss = criterion(outputs.view(B*T, C), batch_y.view(B*T))\n",
    "\n",
    "                preds = outputs.argmax(dim=-1)\n",
    "                mask = (batch_y != diacritic2id['<PAD>'])\n",
    "\n",
    "                correct = (preds[mask] == batch_y[mask]).sum().item()\n",
    "                total = mask.sum().item()\n",
    "\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "                total_train_loss += loss.item()\n",
    "                total_train_correct += correct\n",
    "                total_train_tokens += total\n",
    "\n",
    "                acc = correct / total if total > 0 else 0.0\n",
    "\n",
    "                pbar.set_postfix({\n",
    "                    'Loss': f'{loss.item():.4f}',\n",
    "                    'Acc': f'{acc:.4f}'\n",
    "                })\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        avg_train_acc = total_train_correct / total_train_tokens\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        total_val_correct = 0\n",
    "        total_val_tokens = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            with tqdm(val_loader, desc=f'Epoch {epoch+1}/{epochs} [Val]') as pbar:\n",
    "                for batch_X, batch_y, _, lengths in pbar:\n",
    "                    batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "                    outputs = model(batch_X, lengths)\n",
    "                    B, T, C = outputs.shape\n",
    "\n",
    "                    loss = criterion(outputs.view(B*T, C), batch_y.view(B*T))\n",
    "\n",
    "                    preds = outputs.argmax(dim=-1)\n",
    "                    mask = (batch_y != diacritic2id['<PAD>'])\n",
    "\n",
    "                    correct = (preds[mask] == batch_y[mask]).sum().item()\n",
    "                    total = mask.sum().item()\n",
    "\n",
    "                    total_val_loss += loss.item()\n",
    "                    total_val_correct += correct\n",
    "                    total_val_tokens += total\n",
    "\n",
    "                    acc = correct / total if total > 0 else 0.0\n",
    "\n",
    "                    pbar.set_postfix({\n",
    "                        'Loss': f'{loss.item():.4f}',\n",
    "                        'Acc': f'{acc:.4f}'\n",
    "                    })\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        avg_val_acc = total_val_correct / total_val_tokens\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': best_val_loss,\n",
    "                'val_accuracy': avg_val_acc,\n",
    "                'train_loss': avg_train_loss,\n",
    "                'train_accuracy': avg_train_acc\n",
    "            }, best_model_path)\n",
    "            print(f\"  ‚Ü≥ Best model saved! (val_loss: {best_val_loss:.4f})\")\n",
    "\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{epochs}:')\n",
    "        print(f'  Train Loss: {avg_train_loss:.4f}, Train Acc: {avg_train_acc:.4f}')\n",
    "        print(f'  Val Loss: {avg_val_loss:.4f}, Val Acc: {avg_val_acc:.4f}')\n",
    "        print(f'  LR: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "\n",
    "        train_losses.append(avg_train_loss)\n",
    "        train_accuracies.append(avg_train_acc)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        val_accuracies.append(avg_val_acc)\n",
    "\n",
    "    return {\n",
    "        'train_loss': train_losses,\n",
    "        'train_accuracy': train_accuracies,\n",
    "        'val_loss': val_losses,\n",
    "        'val_accuracy': val_accuracies\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b236a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_collate_fn(batch):\n",
    "    x_batch, y_batch, mask_batch = zip(*batch)\n",
    "    lengths_x = [len(x) for x in x_batch]\n",
    "    x_padded = torch.nn.utils.rnn.pad_sequence(x_batch, batch_first=True, padding_value=letter2idx['<PAD>'])\n",
    "    y_padded = torch.nn.utils.rnn.pad_sequence(y_batch, batch_first=True, padding_value=diacritic2id['<PAD>'])\n",
    "    mask_spadded = torch.nn.utils.rnn.pad_sequence(mask_batch, batch_first=True, padding_value=0)\n",
    "    return x_padded, y_padded, mask_spadded, torch.tensor(lengths_x, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11220db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, train_loader = create_data_pipeline(\n",
    "    corpus_path=str(project_root / 'data/train.txt'), \n",
    "    letter2idx=letter2idx, \n",
    "    diacritic2idx=diacritic2id, \n",
    "    collate_fn=pad_collate_fn,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "val_dataset, val_loader = create_data_pipeline(\n",
    "    corpus_path=str(project_root / 'data/val.txt'), \n",
    "    letter2idx=letter2idx, \n",
    "    diacritic2idx=diacritic2id,\n",
    "    collate_fn=pad_collate_fn,\n",
    "    train=False, \n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bcbae48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_data_statistics(train_dataset, val_dataset, train_loader, val_loader, letter2idx, diacritic2id):\n",
    "    print(\"=\"*80)\n",
    "    print(\" \" * 25 + \"üìä DATA STATISTICS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    train_lengths = [len(x) for x, _, _ in train_dataset]\n",
    "    val_lengths = [len(x) for x, _, _ in val_dataset]\n",
    "    \n",
    "    print(f\"\\n{'Dataset Sizes:':<30}\")\n",
    "    print(f\"  {'Training samples:':<28} {len(train_dataset):>10,}\")\n",
    "    print(f\"  {'Validation samples:':<28} {len(val_dataset):>10,}\")\n",
    "    print(f\"  {'Total samples:':<28} {len(train_dataset) + len(val_dataset):>10,}\")\n",
    "    print(f\"  {'Train/Val ratio:':<28} {len(train_dataset)/len(val_dataset):>10.2f}\")\n",
    "    \n",
    "    print(f\"\\n{'Batch Information:':<30}\")\n",
    "    print(f\"  {'Training batches:':<28} {len(train_loader):>10,}\")\n",
    "    print(f\"  {'Validation batches:':<28} {len(val_loader):>10,}\")\n",
    "    print(f\"  {'Batch size:':<28} {train_loader.batch_size:>10}\")\n",
    "    \n",
    "    print(f\"\\n{'Training Sequence Lengths:':<30}\")\n",
    "    print(f\"  {'Min length:':<28} {min(train_lengths):>10}\")\n",
    "    print(f\"  {'Max length:':<28} {max(train_lengths):>10}\")\n",
    "    print(f\"  {'Mean length:':<28} {np.mean(train_lengths):>10.2f}\")\n",
    "    print(f\"  {'Median length:':<28} {np.median(train_lengths):>10.0f}\")\n",
    "    print(f\"  {'Std deviation:':<28} {np.std(train_lengths):>10.2f}\")\n",
    "    print(f\"  {'25th percentile:':<28} {np.percentile(train_lengths, 25):>10.0f}\")\n",
    "    print(f\"  {'75th percentile:':<28} {np.percentile(train_lengths, 75):>10.0f}\")\n",
    "    print(f\"  {'95th percentile:':<28} {np.percentile(train_lengths, 95):>10.0f}\")\n",
    "    print(f\"  {'99th percentile:':<28} {np.percentile(train_lengths, 99):>10.0f}\")\n",
    "    \n",
    "    print(f\"\\n{'Validation Sequence Lengths:':<30}\")\n",
    "    print(f\"  {'Min length:':<28} {min(val_lengths):>10}\")\n",
    "    print(f\"  {'Max length:':<28} {max(val_lengths):>10}\")\n",
    "    print(f\"  {'Mean length:':<28} {np.mean(val_lengths):>10.2f}\")\n",
    "    print(f\"  {'Median length:':<28} {np.median(val_lengths):>10.0f}\")\n",
    "    print(f\"  {'Std deviation:':<28} {np.std(val_lengths):>10.2f}\")\n",
    "    \n",
    "    print(f\"\\n{'Vocabulary Information:':<30}\")\n",
    "    print(f\"  {'Vocabulary size:':<28} {len(letter2idx):>10}\")\n",
    "    print(f\"  {'Number of diacritics:':<28} {len(diacritic2id):>10}\")\n",
    "    print(f\"  {'Special tokens:':<28} {'<PAD>, <UNK>':>10}\")\n",
    "    \n",
    "    total_train_chars = sum(train_lengths)\n",
    "    total_val_chars = sum(val_lengths)\n",
    "    print(f\"\\n{'Total Characters:':<30}\")\n",
    "    print(f\"  {'Training characters:':<28} {total_train_chars:>10,}\")\n",
    "    print(f\"  {'Validation characters:':<28} {total_val_chars:>10,}\")\n",
    "    print(f\"  {'Total characters:':<28} {total_train_chars + total_val_chars:>10,}\")\n",
    "    \n",
    "    print(f\"\\n{'Memory Estimates (approx):':<30}\")\n",
    "    avg_train_len = np.mean(train_lengths)\n",
    "    avg_val_len = np.mean(val_lengths)\n",
    "    train_batch_mem = train_loader.batch_size * max(train_lengths) * 4 / (1024**2)  # 4 bytes per int\n",
    "    val_batch_mem = val_loader.batch_size * max(val_lengths) * 4 / (1024**2)\n",
    "    print(f\"  {'Max train batch (input):':<28} {train_batch_mem:>9.2f} MB\")\n",
    "    print(f\"  {'Max val batch (input):':<28} {val_batch_mem:>9.2f} MB\")\n",
    "    \n",
    "    print(f\"\\n{'Sequence Length Distribution:':<30}\")\n",
    "    bins = [0, 50, 100, 200, 300, 400, 512]\n",
    "    print(f\"  {'Range':<15} {'Train':<15} {'Val':<15}\")\n",
    "    for i in range(len(bins) - 1):\n",
    "        train_count = sum(1 for l in train_lengths if bins[i] < l <= bins[i+1])\n",
    "        val_count = sum(1 for l in val_lengths if bins[i] < l <= bins[i+1])\n",
    "        train_pct = (train_count / len(train_lengths)) * 100\n",
    "        val_pct = (val_count / len(val_lengths)) * 100\n",
    "        print(f\"  {f'{bins[i]}-{bins[i+1]}':<15} {f'{train_count:,} ({train_pct:.1f}%)':<15} {f'{val_count:,} ({val_pct:.1f}%)':<15}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚úì Data statistics computed successfully!\")\n",
    "    print(\"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33bf4778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "                         üìä DATA STATISTICS\n",
      "================================================================================\n",
      "\n",
      "Dataset Sizes:                \n",
      "  Training samples:               183,466\n",
      "  Validation samples:               8,921\n",
      "  Total samples:                  192,387\n",
      "  Train/Val ratio:                  20.57\n",
      "\n",
      "Batch Information:            \n",
      "  Training batches:                 5,734\n",
      "  Validation batches:                 279\n",
      "  Batch size:                          32\n",
      "\n",
      "Training Sequence Lengths:    \n",
      "  Min length:                           3\n",
      "  Max length:                         512\n",
      "  Mean length:                      54.89\n",
      "  Median length:                       33\n",
      "  Std deviation:                    69.46\n",
      "  25th percentile:                     16\n",
      "  75th percentile:                     65\n",
      "  95th percentile:                    178\n",
      "  99th percentile:                    385\n",
      "\n",
      "Validation Sequence Lengths:  \n",
      "  Min length:                           3\n",
      "  Max length:                         512\n",
      "  Mean length:                      55.03\n",
      "  Median length:                       34\n",
      "  Std deviation:                    68.50\n",
      "\n",
      "Vocabulary Information:       \n",
      "  Vocabulary size:                     38\n",
      "  Number of diacritics:                16\n",
      "  Special tokens:              <PAD>, <UNK>\n",
      "\n",
      "Total Characters:             \n",
      "  Training characters:         10,070,377\n",
      "  Validation characters:          490,922\n",
      "  Total characters:            10,561,299\n",
      "\n",
      "Memory Estimates (approx):    \n",
      "  Max train batch (input):          0.06 MB\n",
      "  Max val batch (input):            0.06 MB\n",
      "\n",
      "Sequence Length Distribution: \n",
      "  Range           Train           Val            \n",
      "  0-50            121,080 (66.0%) 5,837 (65.4%)  \n",
      "  50-100          37,482 (20.4%)  1,881 (21.1%)  \n",
      "  100-200         17,570 (9.6%)   846 (9.5%)     \n",
      "  200-300         4,111 (2.2%)    205 (2.3%)     \n",
      "  300-400         1,553 (0.8%)    77 (0.9%)      \n",
      "  400-512         1,670 (0.9%)    75 (0.8%)      \n",
      "\n",
      "================================================================================\n",
      "‚úì Data statistics computed successfully!\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_data_statistics(\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    letter2idx=letter2idx,\n",
    "    diacritic2id=diacritic2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92527ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture:\n",
      "BiLSTM(\n",
      "  (embedding): Embedding(38, 256, padding_idx=13)\n",
      "  (bilstm): LSTM(256, 256, num_layers=3, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "  (emb_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  (lstm_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc1_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  (fc2): Linear(in_features=256, out_features=16, bias=True)\n",
      ")\n",
      "\n",
      "Total parameters: 4,353,808\n",
      "Trainable parameters: 4,353,808\n"
     ]
    }
   ],
   "source": [
    "model = BiLSTM(vocab_size=vocab_size, num_classes=num_classes).to(device)\n",
    "\n",
    "print(\"Model architecture:\")\n",
    "print(model)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f6cc0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nModel Summary:\n",
      "Total parameters: 4,353,808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5734/5734 [04:00<00:00, 23.83it/s, Loss=0.0904, Acc=0.9683]\n",
      "Epoch 1/10 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 279/279 [00:03<00:00, 77.40it/s, Loss=0.1203, Acc=0.9641]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Ü≥ Best model saved! (val_loss: 0.0908)\n",
      "Epoch 1/10:\n",
      "  Train Loss: 0.1495, Train Acc: 0.9497\n",
      "  Val Loss: 0.0908, Val Acc: 0.9699\n",
      "  LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5734/5734 [04:03<00:00, 23.59it/s, Loss=0.0772, Acc=0.9685]\n",
      "Epoch 2/10 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 279/279 [00:03<00:00, 76.76it/s, Loss=0.1325, Acc=0.9567]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Ü≥ Best model saved! (val_loss: 0.0770)\n",
      "Epoch 2/10:\n",
      "  Train Loss: 0.0871, Train Acc: 0.9709\n",
      "  Val Loss: 0.0770, Val Acc: 0.9749\n",
      "  LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5734/5734 [03:59<00:00, 23.91it/s, Loss=0.1232, Acc=0.9582]\n",
      "Epoch 3/10 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 279/279 [00:03<00:00, 79.30it/s, Loss=0.1103, Acc=0.9622]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Ü≥ Best model saved! (val_loss: 0.0718)\n",
      "Epoch 3/10:\n",
      "  Train Loss: 0.0760, Train Acc: 0.9746\n",
      "  Val Loss: 0.0718, Val Acc: 0.9770\n",
      "  LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5734/5734 [03:59<00:00, 23.92it/s, Loss=0.0397, Acc=0.9917]\n",
      "Epoch 4/10 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 279/279 [00:03<00:00, 76.93it/s, Loss=0.1097, Acc=0.9687]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Ü≥ Best model saved! (val_loss: 0.0690)\n",
      "Epoch 4/10:\n",
      "  Train Loss: 0.0699, Train Acc: 0.9766\n",
      "  Val Loss: 0.0690, Val Acc: 0.9779\n",
      "  LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5734/5734 [04:03<00:00, 23.56it/s, Loss=0.0690, Acc=0.9737]\n",
      "Epoch 5/10 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 279/279 [00:03<00:00, 74.32it/s, Loss=0.1039, Acc=0.9668]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Ü≥ Best model saved! (val_loss: 0.0669)\n",
      "Epoch 5/10:\n",
      "  Train Loss: 0.0661, Train Acc: 0.9779\n",
      "  Val Loss: 0.0669, Val Acc: 0.9785\n",
      "  LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5734/5734 [04:02<00:00, 23.61it/s, Loss=0.0620, Acc=0.9851]\n",
      "Epoch 6/10 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 279/279 [00:03<00:00, 78.17it/s, Loss=0.0975, Acc=0.9696]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Ü≥ Best model saved! (val_loss: 0.0664)\n",
      "Epoch 6/10:\n",
      "  Train Loss: 0.0632, Train Acc: 0.9788\n",
      "  Val Loss: 0.0664, Val Acc: 0.9791\n",
      "  LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 [Train]:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5224/5734 [03:42<00:21, 23.43it/s, Loss=0.0351, Acc=0.9869]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mnModel Summary:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTotal parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(p.numel()\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mp\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mmodel.parameters())\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m history = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m plt.figure(figsize=(\u001b[32m12\u001b[39m, \u001b[32m4\u001b[39m))\n\u001b[32m      8\u001b[39m plt.subplot(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, val_loader, epochs, learning_rate)\u001b[39m\n\u001b[32m     23\u001b[39m batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n\u001b[32m     25\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m B, T, C = outputs.shape\n\u001b[32m     30\u001b[39m loss = criterion(outputs.view(B*T, C), batch_y.view(B*T))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/Arabic-Diacritization/models/mohamed_ashraf/bilstm3.py:44\u001b[39m, in \u001b[36mBiLSTM.forward\u001b[39m\u001b[34m(self, x, lengths)\u001b[39m\n\u001b[32m     35\u001b[39m x_sorted = x_emb[sorted_idx]\n\u001b[32m     37\u001b[39m x_packed = nn.utils.rnn.pack_padded_sequence(\n\u001b[32m     38\u001b[39m     x_sorted, \n\u001b[32m     39\u001b[39m     lengths_sorted.cpu(), \n\u001b[32m     40\u001b[39m     batch_first=\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[32m     41\u001b[39m     enforce_sorted=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     42\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m lstm_packed, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbilstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_packed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m lstm_out, _ = nn.utils.rnn.pad_packed_sequence(\n\u001b[32m     47\u001b[39m     lstm_packed, \n\u001b[32m     48\u001b[39m     batch_first=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     49\u001b[39m     padding_value=\u001b[32m0.0\u001b[39m,\n\u001b[32m     50\u001b[39m     total_length=x_emb.size(\u001b[32m1\u001b[39m)\n\u001b[32m     51\u001b[39m )\n\u001b[32m     53\u001b[39m _, unsorted_idx = sorted_idx.sort()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/env/lib/python3.12/site-packages/torch/nn/modules/rnn.py:1135\u001b[39m, in \u001b[36mLSTM.forward\u001b[39m\u001b[34m(self, input, hx)\u001b[39m\n\u001b[32m   1123\u001b[39m     result = _VF.lstm(\n\u001b[32m   1124\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   1125\u001b[39m         hx,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1132\u001b[39m         \u001b[38;5;28mself\u001b[39m.batch_first,\n\u001b[32m   1133\u001b[39m     )\n\u001b[32m   1134\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1135\u001b[39m     result = \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1136\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1137\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1138\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1139\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1140\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1141\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1142\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1143\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1144\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1145\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1146\u001b[39m output = result[\u001b[32m0\u001b[39m]\n\u001b[32m   1147\u001b[39m hidden = result[\u001b[32m1\u001b[39m:]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "print(\"\\\\nModel Summary:\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "history = train_model(model, train_loader, val_loader, epochs=10)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_accuracy'], label='Training Accuracy')\n",
    "plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_loss'], label='Training Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'vocab_size': vocab_size,\n",
    "    'num_classes': num_classes,\n",
    "    'history': history\n",
    "}, 'bilstm_model.pth')\n",
    "\n",
    "print(\"Model saved successfully as 'bilstm_model.pth'!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
