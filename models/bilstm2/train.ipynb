{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e7e7eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root added to path: /home/mohamed-ashraf/Desktop/projects/Arabic-Diacritization\n",
      "Current working directory: /home/mohamed-ashraf/Desktop/projects/Arabic-Diacritization/models/bilstm2\n"
     ]
    }
   ],
   "source": [
    "# Setup Python path to include project root\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to Python path (go up 2 levels from current notebook location)\n",
    "project_root = Path.cwd().parent.parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"Project root added to path: {project_root}\")\n",
    "print(f\"Current working directory: {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58284479",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 17:18:43.633764: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-04 17:18:43.670816: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-04 17:18:44.671245: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from utils.utils import create_data_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44d41ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "821762c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ظ': 0, 'ي': 1, 'غ': 2, 'ن': 3, 'ق': 4, 'ذ': 5, 'د': 6, 'خ': 7, 'ر': 8, 'ط': 9, 'ى': 10, 'م': 11, 'ل': 12, '<PAD>': 13, 'ت': 14, 'ج': 15, 'آ': 16, 'ا': 17, 'س': 18, 'ئ': 19, 'ع': 20, 'ف': 21, 'ص': 22, 'ه': 23, 'ز': 24, 'ك': 25, 'ش': 26, 'أ': 27, 'و': 28, 'ب': 29, 'ؤ': 30, 'ض': 31, 'ة': 32, 'ث': 33, 'ء': 34, 'ح': 35, 'إ': 36, ' ': 37}\n",
      "{0: 'ظ', 1: 'ي', 2: 'غ', 3: 'ن', 4: 'ق', 5: 'ذ', 6: 'د', 7: 'خ', 8: 'ر', 9: 'ط', 10: 'ى', 11: 'م', 12: 'ل', 13: '<PAD>', 14: 'ت', 15: 'ج', 16: 'آ', 17: 'ا', 18: 'س', 19: 'ئ', 20: 'ع', 21: 'ف', 22: 'ص', 23: 'ه', 24: 'ز', 25: 'ك', 26: 'ش', 27: 'أ', 28: 'و', 29: 'ب', 30: 'ؤ', 31: 'ض', 32: 'ة', 33: 'ث', 34: 'ء', 35: 'ح', 36: 'إ', 37: ' '}\n",
      "{'َ': 0, 'ً': 1, 'ُ': 2, 'ٌ': 3, 'ِ': 4, 'ٍ': 5, 'ْ': 6, 'ّ': 7, 'َّ': 8, 'ًّ': 9, 'ُّ': 10, 'ٌّ': 11, 'ِّ': 12, 'ٍّ': 13, '': 14, '<PAD>': 15}\n",
      "{0: 'َ', 1: 'ً', 2: 'ُ', 3: 'ٌ', 4: 'ِ', 5: 'ٍ', 6: 'ْ', 7: 'ّ', 8: 'َّ', 9: 'ًّ', 10: 'ُّ', 11: 'ٌّ', 12: 'ِّ', 13: 'ٍّ', 14: '', 15: '<PAD>'}\n"
     ]
    }
   ],
   "source": [
    "with open(project_root / \"utils/letter2idx.pickle\", \"rb\") as file:\n",
    "    letter2idx = pickle.load(file)\n",
    "\n",
    "with open(project_root / \"utils/diacritic2id.pickle\", \"rb\") as file:\n",
    "    diacritic2id = pickle.load(file)\n",
    "\n",
    "idx2letter = {value: key for key, value in letter2idx.items()}\n",
    "idx2diacritic = {value: key for key, value in diacritic2id.items()}\n",
    "\n",
    "print(letter2idx)\n",
    "print(idx2letter)\n",
    "print(diacritic2id)\n",
    "print(idx2diacritic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c315df86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 38\n",
      "Num classes: 16\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(letter2idx) \n",
    "num_classes = len(diacritic2id)\n",
    "print(\"Vocab size:\", vocab_size)\n",
    "print(\"Num classes:\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff100b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_dynamic(model, train_loader, val_loader, epochs=10, learning_rate=0.001):\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=diacritic2id['<PAD>'])\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5)\n",
    "    \n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_model_path = 'best_dynamic_blstm_model.pth'\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        total_train_loss = 0\n",
    "        total_train_correct = 0\n",
    "        total_train_tokens = 0\n",
    "\n",
    "        with tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs} [Train]') as pbar:\n",
    "            for batch_X, batch_y, _, lengths in pbar:\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(batch_X, lengths)\n",
    "\n",
    "                B, T, C = outputs.shape\n",
    "                loss = criterion(outputs.view(B*T, C), batch_y.view(B*T))\n",
    "\n",
    "                preds = outputs.argmax(dim=-1)\n",
    "                mask = (batch_y != diacritic2id['<PAD>'])\n",
    "\n",
    "                correct = (preds[mask] == batch_y[mask]).sum().item()\n",
    "                total = mask.sum().item()\n",
    "\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "                total_train_loss += loss.item()\n",
    "                total_train_correct += correct\n",
    "                total_train_tokens += total\n",
    "\n",
    "                acc = correct / total if total > 0 else 0.0\n",
    "\n",
    "                pbar.set_postfix({\n",
    "                    'Loss': f'{loss.item():.4f}',\n",
    "                    'Acc': f'{acc:.4f}'\n",
    "                })\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        avg_train_acc = total_train_correct / total_train_tokens\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        total_val_correct = 0\n",
    "        total_val_tokens = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            with tqdm(val_loader, desc=f'Epoch {epoch+1}/{epochs} [Val]') as pbar:\n",
    "                for batch_X, batch_y, _, lengths in pbar:\n",
    "                    batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "                    outputs = model(batch_X, lengths)\n",
    "                    B, T, C = outputs.shape\n",
    "\n",
    "                    loss = criterion(outputs.view(B*T, C), batch_y.view(B*T))\n",
    "\n",
    "                    preds = outputs.argmax(dim=-1)\n",
    "                    mask = (batch_y != diacritic2id['<PAD>'])\n",
    "\n",
    "                    correct = (preds[mask] == batch_y[mask]).sum().item()\n",
    "                    total = mask.sum().item()\n",
    "\n",
    "                    total_val_loss += loss.item()\n",
    "                    total_val_correct += correct\n",
    "                    total_val_tokens += total\n",
    "\n",
    "                    acc = correct / total if total > 0 else 0.0\n",
    "\n",
    "                    pbar.set_postfix({\n",
    "                        'Loss': f'{loss.item():.4f}',\n",
    "                        'Acc': f'{acc:.4f}'\n",
    "                    })\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        avg_val_acc = total_val_correct / total_val_tokens\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': best_val_loss,\n",
    "                'val_accuracy': avg_val_acc,\n",
    "                'train_loss': avg_train_loss,\n",
    "                'train_accuracy': avg_train_acc\n",
    "            }, best_model_path)\n",
    "            print(f\"  ↳ Best model saved! (val_loss: {best_val_loss:.4f})\")\n",
    "\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{epochs}:')\n",
    "        print(f'  Train Loss: {avg_train_loss:.4f}, Train Acc: {avg_train_acc:.4f}')\n",
    "        print(f'  Val Loss: {avg_val_loss:.4f}, Val Acc: {avg_val_acc:.4f}')\n",
    "        print(f'  LR: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "\n",
    "        train_losses.append(avg_train_loss)\n",
    "        train_accuracies.append(avg_train_acc)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        val_accuracies.append(avg_val_acc)\n",
    "\n",
    "    return {\n",
    "        'train_loss': train_losses,\n",
    "        'train_accuracy': train_accuracies,\n",
    "        'val_loss': val_losses,\n",
    "        'val_accuracy': val_accuracies\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b236a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_collate_fn(batch):\n",
    "    x_batch, y_batch, mask_batch = zip(*batch)\n",
    "    lengths_x = [len(x) for x in x_batch]\n",
    "    x_padded = torch.nn.utils.rnn.pad_sequence(x_batch, batch_first=True, padding_value=letter2idx['<PAD>'])\n",
    "    y_padded = torch.nn.utils.rnn.pad_sequence(y_batch, batch_first=True, padding_value=diacritic2id['<PAD>'])\n",
    "    mask_spadded = torch.nn.utils.rnn.pad_sequence(mask_batch, batch_first=True, padding_value=0)\n",
    "    return x_padded, y_padded, mask_spadded, torch.tensor(lengths_x, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "399cfbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, num_classes, embedding_dim=256, hidden_size=256, num_layers=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=13)\n",
    "        nn.init.xavier_uniform_(self.embedding.weight)\n",
    "        \n",
    "        self.bilstm = nn.LSTM(\n",
    "            embedding_dim,\n",
    "            hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=0.3 if num_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        self.emb_norm = nn.LayerNorm(embedding_dim)\n",
    "        self.lstm_norm = nn.LayerNorm(hidden_size * 2)\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "        \n",
    "    def forward(self, x, lengths=None):\n",
    "        x_emb = self.embedding(x)\n",
    "        x_emb = self.emb_norm(x_emb)\n",
    "        \n",
    "        if lengths is not None:\n",
    "            lengths_sorted, sorted_idx = lengths.sort(descending=True)\n",
    "            x_sorted = x_emb[sorted_idx]\n",
    "            \n",
    "            x_packed = nn.utils.rnn.pack_padded_sequence(\n",
    "                x_sorted, \n",
    "                lengths_sorted.cpu(), \n",
    "                batch_first=True, \n",
    "                enforce_sorted=True\n",
    "            )\n",
    "            \n",
    "            lstm_packed, _ = self.bilstm(x_packed)\n",
    "            \n",
    "            lstm_out, _ = nn.utils.rnn.pad_packed_sequence(\n",
    "                lstm_packed, \n",
    "                batch_first=True,\n",
    "                padding_value=0.0,\n",
    "                total_length=x_emb.size(1)\n",
    "            )\n",
    "            \n",
    "            _, unsorted_idx = sorted_idx.sort()\n",
    "            lstm_out = lstm_out[unsorted_idx]\n",
    "        else:\n",
    "            lstm_out, _ = self.bilstm(x_emb)\n",
    "        \n",
    "        lstm_out = self.lstm_norm(lstm_out)\n",
    "        out = self.fc(lstm_out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11220db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, train_loader = create_data_pipeline(\n",
    "    corpus_path=str(project_root / 'data/train.txt'), \n",
    "    letter2idx=letter2idx, \n",
    "    diacritic2idx=diacritic2id, \n",
    "    collate_fn=pad_collate_fn,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "val_dataset, val_loader = create_data_pipeline(\n",
    "    corpus_path=str(project_root / 'data/val.txt'), \n",
    "    letter2idx=letter2idx, \n",
    "    diacritic2idx=diacritic2id,\n",
    "    collate_fn=pad_collate_fn,\n",
    "    train=False, \n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92527ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture:\n",
      "BiLSTM(\n",
      "  (embedding): Embedding(38, 256, padding_idx=13)\n",
      "  (bilstm): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
      "  (emb_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  (lstm_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  (fc): Linear(in_features=512, out_features=16, bias=True)\n",
      ")\n",
      "\n",
      "Total parameters: 2,649,104\n",
      "Trainable parameters: 2,649,104\n"
     ]
    }
   ],
   "source": [
    "model = BiLSTM(vocab_size=vocab_size, num_classes=num_classes).to(device)\n",
    "\n",
    "print(\"Model architecture:\")\n",
    "print(model)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6cc0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nModel Summary:\n",
      "Total parameters: 2,649,104\n",
      "\\nStarting training with dynamic sequence lengths...\n"
     ]
    }
   ],
   "source": [
    "# Print model summary\n",
    "print(\"\\\\nModel Summary:\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Train model with dynamic sequences\n",
    "print(\"\\\\nStarting training with dynamic sequence lengths...\")\n",
    "history = train_model_dynamic(model, train_loader, val_loader, epochs=10)\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_accuracy'], label='Training Accuracy')\n",
    "plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_loss'], label='Training Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save model\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'vocab_size': vocab_size,\n",
    "    'num_classes': num_classes,\n",
    "    'history': history\n",
    "}, 'dynamic_blstm_model.pth')\n",
    "\n",
    "print(\"Model saved successfully as 'dynamic_blstm_model.pth'!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
