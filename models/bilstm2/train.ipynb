{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58284479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44d41ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "821762c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"utils/letter2idx.pickle\", \"rb\") as file:\n",
    "    letter2idx = pickle.load(file)\n",
    "\n",
    "with open(\"utils/diacritic2id.pickle\", \"rb\") as file:\n",
    "    diacritic2id = pickle.load(file)\n",
    "\n",
    "idx2letter = {value: key for key, value in letter2idx.items()}\n",
    "idx2diacritic = {value: key for key, value in diacritic2id.items()}\n",
    "\n",
    "print(letter2idx)\n",
    "print(idx2letter)\n",
    "print(diacritic2id)\n",
    "print(idx2diacritic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c315df86",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(letter2idx) \n",
    "num_classes = len(diacritic2id)\n",
    "print(\"Vocab size:\", vocab_size)\n",
    "print(\"Num classes:\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f703246",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"data/X_train.npy\", allow_pickle=True)\n",
    "y_train = np.load(\"data/y_train.npy\", allow_pickle=True)\n",
    "X_val = np.load(\"data/X_val.npy\", allow_pickle=True)\n",
    "y_val = np.load(\"data/y_val.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff100b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_dynamic(model, train_loader, val_loader, epochs=10, learning_rate=0.001):\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=diacritic2id['<PAD>'])\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5)\n",
    "    \n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_model_path = 'best_dynamic_blstm_model.pth'\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        total_train_loss = 0\n",
    "        total_train_correct = 0\n",
    "        total_train_tokens = 0\n",
    "\n",
    "        with tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs} [Train]') as pbar:\n",
    "            for batch_X, batch_y, _, lengths in pbar:\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(batch_X, lengths)\n",
    "\n",
    "                B, T, C = outputs.shape\n",
    "                loss = criterion(outputs.view(B*T, C), batch_y.view(B*T))\n",
    "\n",
    "                preds = outputs.argmax(dim=-1)\n",
    "                mask = (batch_y != diacritic2id['<PAD>'])\n",
    "\n",
    "                correct = (preds[mask] == batch_y[mask]).sum().item()\n",
    "                total = mask.sum().item()\n",
    "\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "                total_train_loss += loss.item()\n",
    "                total_train_correct += correct\n",
    "                total_train_tokens += total\n",
    "\n",
    "                acc = correct / total if total > 0 else 0.0\n",
    "\n",
    "                pbar.set_postfix({\n",
    "                    'Loss': f'{loss.item():.4f}',\n",
    "                    'Acc': f'{acc:.4f}'\n",
    "                })\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        avg_train_acc = total_train_correct / total_train_tokens\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        total_val_correct = 0\n",
    "        total_val_tokens = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            with tqdm(val_loader, desc=f'Epoch {epoch+1}/{epochs} [Val]') as pbar:\n",
    "                for batch_X, batch_y, _, lengths in pbar:\n",
    "                    batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "                    outputs = model(batch_X, lengths)\n",
    "                    B, T, C = outputs.shape\n",
    "\n",
    "                    loss = criterion(outputs.view(B*T, C), batch_y.view(B*T))\n",
    "\n",
    "                    preds = outputs.argmax(dim=-1)\n",
    "                    mask = (batch_y != diacritic2id['<PAD>'])\n",
    "\n",
    "                    correct = (preds[mask] == batch_y[mask]).sum().item()\n",
    "                    total = mask.sum().item()\n",
    "\n",
    "                    total_val_loss += loss.item()\n",
    "                    total_val_correct += correct\n",
    "                    total_val_tokens += total\n",
    "\n",
    "                    acc = correct / total if total > 0 else 0.0\n",
    "\n",
    "                    pbar.set_postfix({\n",
    "                        'Loss': f'{loss.item():.4f}',\n",
    "                        'Acc': f'{acc:.4f}'\n",
    "                    })\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        avg_val_acc = total_val_correct / total_val_tokens\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': best_val_loss,\n",
    "                'val_accuracy': avg_val_acc,\n",
    "                'train_loss': avg_train_loss,\n",
    "                'train_accuracy': avg_train_acc\n",
    "            }, best_model_path)\n",
    "            print(f\"  â†³ Best model saved! (val_loss: {best_val_loss:.4f})\")\n",
    "\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{epochs}:')\n",
    "        print(f'  Train Loss: {avg_train_loss:.4f}, Train Acc: {avg_train_acc:.4f}')\n",
    "        print(f'  Val Loss: {avg_val_loss:.4f}, Val Acc: {avg_val_acc:.4f}')\n",
    "        print(f'  LR: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "\n",
    "        train_losses.append(avg_train_loss)\n",
    "        train_accuracies.append(avg_train_acc)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        val_accuracies.append(avg_val_acc)\n",
    "\n",
    "    return {\n",
    "        'train_loss': train_losses,\n",
    "        'train_accuracy': train_accuracies,\n",
    "        'val_loss': val_losses,\n",
    "        'val_accuracy': val_accuracies\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b236a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_collate_fn(batch):\n",
    "    x_batch, y_batch, mask_batch_padded = zip(*batch)\n",
    "    lengths_x = [len(x) for x in x_batch]\n",
    "    x_padded = torch.nn.utils.rnn.pad_sequence(x_batch, batch_first=True, padding_value=letter2idx['<PAD>'])\n",
    "    y_padded = torch.nn.utils.rnn.pad_sequence(y_batch, batch_first=True, padding_value=diacritic2id['<PAD>'])\n",
    "    mask_stacked = torch.stack(mask_batch_padded, dim=0) \n",
    "    return x_padded, y_padded, mask_stacked, torch.tensor(lengths_x, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c25cca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiacritizationDataset(Dataset):\n",
    "    def __init__(self, X, y, letter2idx):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.pad_idx = letter2idx['<PAD>']\n",
    "        self.space_idx = letter2idx[' ']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x_seq = self.X[idx]\n",
    "        y_seq = self.y[idx]\n",
    "        \n",
    "        mask = np.zeros_like(x_seq, dtype=np.int64)\n",
    "        \n",
    "        pad_positions = np.where(x_seq == self.pad_idx)[0]\n",
    "        if len(pad_positions) > 0:\n",
    "            sentence_end = pad_positions[0]\n",
    "        else:\n",
    "            sentence_end = len(x_seq)\n",
    "\n",
    "        space_positions = np.where(x_seq[:sentence_end] == self.space_idx)[0]\n",
    "        all_boundaries = list(space_positions) + [sentence_end]\n",
    "        \n",
    "        start_idx = 0\n",
    "        for boundary in all_boundaries:\n",
    "            if start_idx < boundary:\n",
    "                last_char_idx = boundary - 1\n",
    "                if x_seq[last_char_idx] != self.pad_idx:\n",
    "                    mask[last_char_idx] = 1\n",
    "            start_idx = boundary + 1\n",
    "        \n",
    "        return (\n",
    "            torch.tensor(x_seq, dtype=torch.long),\n",
    "            torch.tensor(y_seq, dtype=torch.long),\n",
    "            torch.tensor(mask, dtype=torch.long)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "399cfbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, num_classes, embedding_dim=256, hidden_size=256, num_layers=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=13)\n",
    "        nn.init.xavier_uniform_(self.embedding.weight)\n",
    "        \n",
    "        self.bilstm = nn.LSTM(\n",
    "            embedding_dim,\n",
    "            hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=0.3 if num_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        self.emb_norm = nn.LayerNorm(embedding_dim)\n",
    "        self.lstm_norm = nn.LayerNorm(hidden_size * 2)\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "        \n",
    "    def forward(self, x, lengths=None):\n",
    "        x_emb = self.embedding(x)\n",
    "        x_emb = self.emb_norm(x_emb)\n",
    "        \n",
    "        if lengths is not None:\n",
    "            lengths_sorted, sorted_idx = lengths.sort(descending=True)\n",
    "            x_sorted = x_emb[sorted_idx]\n",
    "            \n",
    "            x_packed = nn.utils.rnn.pack_padded_sequence(\n",
    "                x_sorted, \n",
    "                lengths_sorted.cpu(), \n",
    "                batch_first=True, \n",
    "                enforce_sorted=True\n",
    "            )\n",
    "            \n",
    "            lstm_packed, _ = self.bilstm(x_packed)\n",
    "            \n",
    "            lstm_out, _ = nn.utils.rnn.pad_packed_sequence(\n",
    "                lstm_packed, \n",
    "                batch_first=True,\n",
    "                padding_value=0.0,\n",
    "                total_length=x_emb.size(1)\n",
    "            )\n",
    "            \n",
    "            _, unsorted_idx = sorted_idx.sort()\n",
    "            lstm_out = lstm_out[unsorted_idx]\n",
    "        else:\n",
    "            lstm_out, _ = self.bilstm(x_emb)\n",
    "        \n",
    "        lstm_out = self.lstm_norm(lstm_out)\n",
    "        out = self.fc(lstm_out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11220db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_dataset = DiacritizationDataset(X_train, y_train, letter2idx)\n",
    "val_text_dataset = DiacritizationDataset(X_val, y_val, letter2idx)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(\n",
    "    train_text_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    collate_fn=pad_collate_fn\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_text_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    collate_fn=pad_collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92527ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiLSTM(vocab_size=vocab_size, num_classes=num_classes).to(device)\n",
    "\n",
    "print(\"Model architecture:\")\n",
    "print(model)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f6cc0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model summary\n",
    "print(\"\\\\nModel Summary:\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Train model with dynamic sequences\n",
    "print(\"\\\\nStarting training with dynamic sequence lengths...\")\n",
    "history = train_model_dynamic(model, train_loader, val_loader, epochs=10)\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_accuracy'], label='Training Accuracy')\n",
    "plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_loss'], label='Training Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save model\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'vocab_size': vocab_size,\n",
    "    'num_classes': num_classes,\n",
    "    'history': history\n",
    "}, 'dynamic_blstm_model.pth')\n",
    "\n",
    "print(\"Model saved successfully as 'dynamic_blstm_model.pth'!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
