{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "723cbbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from utils.utils import create_data_pipeline\n",
    "from models.mohamed_ashraf.bilstm3 import BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e1c8970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56058935",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('utils/diacritic2id.pickle', 'rb') as f:\n",
    "    diacritic2idx = pickle.load(f)\n",
    "\n",
    "with open('utils/letter2idx.pickle', 'rb') as f:\n",
    "    letter2idx = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "258275d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 38, Number of classes: 16\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(letter2idx)\n",
    "num_classes = len(diacritic2idx)\n",
    "\n",
    "print(f\"Vocab size: {vocab_size}, Number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3b47936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_collate_fn(batch):\n",
    "    x_batch, y_batch, mask_batch = zip(*batch)\n",
    "    lengths_x = [len(x) for x in x_batch]\n",
    "    x_padded = torch.nn.utils.rnn.pad_sequence(x_batch, batch_first=True, padding_value=letter2idx['<PAD>'])\n",
    "    y_padded = torch.nn.utils.rnn.pad_sequence(y_batch, batch_first=True, padding_value=diacritic2idx['<PAD>'])\n",
    "    mask_spadded = torch.nn.utils.rnn.pad_sequence(mask_batch, batch_first=True, padding_value=0)\n",
    "    return x_padded, y_padded, mask_spadded, torch.tensor(lengths_x, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff2682fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset,  test_loader= create_data_pipeline(\n",
    "    corpus_path='dataset_no_diacritics.txt', \n",
    "    letter2idx=letter2idx, \n",
    "    diacritic2idx=diacritic2idx, \n",
    "    collate_fn=pad_collate_fn,\n",
    "    train=False, \n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91541940",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiLSTM(vocab_size=vocab_size, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "317e1a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87164/4275060375.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"./models/mohamed_ashraf/bilstm3.pth\", map_location=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BiLSTM(\n",
       "  (embedding): Embedding(38, 256, padding_idx=13)\n",
       "  (bilstm): LSTM(256, 256, num_layers=3, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (emb_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  (lstm_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc1): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc1_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  (fc2): Linear(in_features=256, out_features=16, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"./models/mohamed_ashraf/bilstm3.pth\", map_location=device)\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)\n",
    "\n",
    "# print(f\"Loaded checkpoint from epoch {checkpoint['epoch']}\")\n",
    "# print(f\"Validation Loss: {checkpoint['val_loss']:.4f}\")\n",
    "# print(f\"Validation Accuracy: {checkpoint['val_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a729254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_predictions_csv(model, test_loader, letter2idx, output_file='predictions.csv'):\n",
    "    model.eval()\n",
    "    space_idx = letter2idx.get(' ', None)\n",
    "    pad_idx = letter2idx.get('<PAD>', None)\n",
    "    \n",
    "    idx2letter = {v: k for k, v in letter2idx.items()}\n",
    "    \n",
    "    results = []\n",
    "    row_id = 0\n",
    "    line_number = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_X, _, batch_mask, lengths in test_loader:\n",
    "            batch_X = batch_X.to(device)\n",
    "            \n",
    "            outputs = model(batch_X, lengths)\n",
    "            preds = outputs.argmax(dim=-1)\n",
    "            \n",
    "            batch_X_cpu = batch_X.cpu().numpy()\n",
    "            preds_cpu = preds.cpu().numpy()\n",
    "            batch_mask_cpu = batch_mask.cpu().numpy()\n",
    "            \n",
    "            for i in range(batch_X.size(0)):\n",
    "                seq_len = lengths[i].item()\n",
    "                \n",
    "                for j in range(seq_len):\n",
    "                    letter_idx = int(batch_X_cpu[i, j])\n",
    "                    diacritic_idx = int(preds_cpu[i, j])\n",
    "                    mask_value = int(batch_mask_cpu[i, j])\n",
    "                    \n",
    "                    if letter_idx == pad_idx:\n",
    "                        continue\n",
    "                    \n",
    "                    if letter_idx == space_idx:\n",
    "                        line_number += 1\n",
    "                        continue\n",
    "                    \n",
    "                    letter = idx2letter.get(letter_idx, '<UNK>')\n",
    "                    \n",
    "                    case_ending = True if mask_value == 1 else False\n",
    "                    \n",
    "                    results.append({\n",
    "                        'ID': row_id,\n",
    "                        'line_number': line_number,\n",
    "                        'letter': letter,\n",
    "                        'case_ending': case_ending,\n",
    "                        'label': diacritic_idx\n",
    "                    })\n",
    "                    row_id += 1\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4fed1403",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = create_predictions_csv(\n",
    "    model=model,\n",
    "    test_loader=test_loader,\n",
    "    letter2idx=letter2idx,\n",
    "    output_file='predictions.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7175ef7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current predictions.csv columns:\n",
      "['ID', 'line_number', 'letter', 'case_ending', 'label']\n",
      "\n",
      "Shape: (237240, 5)\n",
      "\n",
      "First few rows:\n",
      "   ID  line_number letter  case_ending  label\n",
      "0   0            0      ŸÅ        False      4\n",
      "1   1            0      Ÿä         True     14\n",
      "2   2            1      ÿß        False     14\n",
      "3   3            1      ŸÑ        False      6\n",
      "4   4            1      ŸÖ        False      0\n"
     ]
    }
   ],
   "source": [
    "print(\"Current predictions.csv columns:\")\n",
    "print(predictions_df.columns.tolist())\n",
    "print(f\"\\nShape: {predictions_df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(predictions_df.head())\n",
    "\n",
    "def create_kaggle_submission(predictions_df, output_file='submission.csv'):\n",
    "    submission_df = predictions_df[['ID', 'label']].copy()\n",
    "    \n",
    "    submission_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    return submission_df\n",
    "\n",
    "submission_df = create_kaggle_submission(predictions_df, 'submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f60118df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created submission_ce.csv\n",
      "   Total rows with case_ending=True: 56,736\n",
      "   Columns: ['ID', 'label']\n",
      "\n",
      "üìä First few rows:\n",
      "    ID  label\n",
      "1    1     14\n",
      "7    7      4\n",
      "12  12     12\n",
      "18  18      4\n",
      "20  20      6\n"
     ]
    }
   ],
   "source": [
    "def create_case_ending_submission(predictions_df, output_file='submission_ce.csv'):\n",
    "    \"\"\"\n",
    "    Create a submission file with only rows where case_ending is True.\n",
    "    \n",
    "    Args:\n",
    "        predictions_df: DataFrame with columns ['ID', 'line_number', 'letter', 'case_ending', 'label']\n",
    "        output_file: Output CSV filename (default: 'submission_ce.csv')\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with only case_ending=True rows, containing ['ID', 'label'] columns\n",
    "    \"\"\"\n",
    "    # Filter rows where case_ending is True\n",
    "    ce_df = predictions_df[predictions_df['case_ending'] == True].copy()\n",
    "    \n",
    "    # Select only ID and label columns for submission\n",
    "    submission_ce_df = ce_df[['ID', 'label']].copy()\n",
    "    \n",
    "    # Save to CSV\n",
    "    submission_ce_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"‚úÖ Created {output_file}\")\n",
    "    print(f\"   Total rows with case_ending=True: {len(submission_ce_df):,}\")\n",
    "    print(f\"   Columns: {submission_ce_df.columns.tolist()}\")\n",
    "    print(f\"\\nüìä First few rows:\")\n",
    "    print(submission_ce_df.head())\n",
    "    \n",
    "    return submission_ce_df\n",
    "\n",
    "# Create the case ending submission file\n",
    "submission_ce_df = create_case_ending_submission(predictions_df, 'submission_ce.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
